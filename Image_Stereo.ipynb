{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","cell_execution_strategy":"setup","authorship_tag":"ABX9TyN53PRops1fJ4jedI+DLxAM"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"V58IJcVA4UGV"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["pip install opencv-python opencv-contrib-python numpy\n"],"metadata":{"id":"rpNdmmzA4n78"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import matplotlib.pyplot as plt\n","\n","# Lecture des deux images\n","input1 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imLeft.png') # image de gauche\n","input2 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imRight.png') # image de droite\n","\n","# Convertir les images en RGB pour l'affichage avec Matplotlib\n","input1_rgb = cv2.cvtColor(input1, cv2.COLOR_BGR2RGB)\n","input2_rgb = cv2.cvtColor(input2, cv2.COLOR_BGR2RGB)\n","\n","# Afficher les images en couleur avec les coordonnées\n","plt.figure(figsize=(15, 5))\n","\n","plt.subplot(1, 2, 1)\n","plt.imshow(input1_rgb)\n","plt.title('Image Gauche')\n","plt.xlabel('Coordonnées en pixels')\n","plt.ylabel('Coordonnées en pixels')\n","\n","\n","plt.subplot(1, 2, 2)\n","plt.imshow(input2_rgb)\n","plt.title('Image Droite')\n","plt.xlabel('Coordonnées en pixels')\n","plt.ylabel('Coordonnées en pixels')\n","\n","\n","plt.show()\n"],"metadata":{"id":"HC3-T154qJoU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import matplotlib.pyplot as plt\n","\n","# Lecture des deux images\n","input1 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imLeft.png') # image de gauche\n","input2 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imRight.png') # image de droite\n","\n","# Conversion en niveaux de gris\n","img1 = cv2.cvtColor(input1, cv2.COLOR_BGR2GRAY)\n","img2 = cv2.cvtColor(input2, cv2.COLOR_BGR2GRAY)\n","\n","# Initialiser le détecteur SIFT\n","sift = cv2.SIFT_create(nfeatures=2000)\n","\n","# Détecter les points d'intérêt et les descripteurs\n","kp1, des1 = sift.detectAndCompute(img1, None)\n","kp2, des2 = sift.detectAndCompute(img2, None)\n","\n","# Dessiner les points d'intérêt sur les images\n","img1_keypoints = cv2.drawKeypoints(img1, kp1, None, color=(0, 255, 0), flags=0)\n","img2_keypoints = cv2.drawKeypoints(img2, kp2, None, color=(0, 255, 0), flags=0)\n","\n","# Afficher les images avec les points d'intérêt\n","plt.figure(figsize=(15, 10))\n","\n","plt.subplot(1, 2, 1)\n","plt.imshow(img1_keypoints, cmap='gray')\n","plt.title('Points SIFT (Image de gauche)')\n","plt.axis('off')\n","\n","plt.subplot(1, 2, 2)\n","plt.imshow(img2_keypoints, cmap='gray')\n","plt.title('Points SIFT (Image de droite)')\n","plt.axis('off')\n","\n","plt.show()\n"],"metadata":{"id":"lVKHhi4Mh4l9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import matplotlib.pyplot as plt\n","\n","# Lire les images\n","img1 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imLeft.png', cv2.IMREAD_GRAYSCALE)\n","img2 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imRight.png', cv2.IMREAD_GRAYSCALE)\n","\n","# Initialiser le détecteur SIFT\n","sift = cv2.SIFT_create()\n","\n","# Détecter les points d'intérêt et les descripteurs\n","keypoints_1 = sift.detect(img1, None)\n","keypoints_2 = sift.detect(img2, None)\n","\n","# Dessiner les points d'intérêt sur les images\n","img1_keypoints = cv2.drawKeypoints(img1, keypoints_1, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n","img2_keypoints = cv2.drawKeypoints(img2, keypoints_2, None, flags=cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n","\n","# Afficher les images avec les points d'intérêt\n","plt.figure(figsize=(15, 10))\n","\n","plt.subplot(1, 2, 1)\n","plt.imshow(img1_keypoints, cmap='gray')\n","plt.title('Points d\\'intérêt - Image gauche')\n","plt.axis('off')\n","\n","plt.subplot(1, 2, 2)\n","plt.imshow(img2_keypoints, cmap='gray')\n","plt.title('Points d\\'intérêt - Image droite')\n","plt.axis('off')\n","\n","plt.show()\n"],"metadata":{"id":"9FDnfcsgeX4L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","###### Lecture des deux images\n","input1 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imLeft.png') # image de gauche\n","input2 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imRight.png') # image de droite\n","\n","# Conversion en niveaux de gris\n","img1 = cv2.cvtColor(input1, cv2.COLOR_BGR2GRAY)\n","img2 = cv2.cvtColor(input2, cv2.COLOR_BGR2GRAY)\n","\n","###### Détection des points clefs\n","sift = cv2.SIFT_create()\n","\n","# Détection des points SIFT et calcul des descripteurs\n","kp1, des1 = sift.detectAndCompute(img1, None)\n","kp2, des2 = sift.detectAndCompute(img2, None)\n","\n","print('Nb de SIFT : ' + str(len(kp1)) + ' (gauche) ' + str(len(kp2)) + ' (droite)')\n","imgd = cv2.drawKeypoints(img1, kp1, None, flags=cv2.DrawMatchesFlags_DRAW_RICH_KEYPOINTS)\n","plt.imshow(imgd), plt.title('%i Points SIFT (Image de gauche)' % len(kp1))\n","plt.show()\n","\n","pts1 = []\n","pts2 = []\n","\n","# Distance L2 pour descripteur SIFT\n","bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n","# Extraction de la liste des 2-plus-proches-voisins\n","matches = bf.knnMatch(des1, des2, k=2)\n","# Filtrage des appariements par application du ratio test avec un seuil plus permissif\n","good = []\n","bad = []\n","for m, n in matches:\n","    if m.distance < 0.75 * n.distance:\n","        pts2.append(kp2[m.trainIdx].pt)\n","        pts1.append(kp1[m.queryIdx].pt)\n","        good.append([m])\n","    else:\n","        bad.append([m])\n","\n","mfilt_image_good = np.array([])\n","mfilt_image_bad = np.array([])\n","draw_params_good = dict(matchColor=(0, 255, 0),\n","                        singlePointColor=(255, 0, 0),\n","                        flags=0)\n","draw_params_bad = dict(matchColor=(0, 0, 255),\n","                       singlePointColor=(255, 0, 0),\n","                       flags=0)\n","\n","mfilt_image_good = cv2.drawMatchesKnn(img1, kp1, img2, kp2, good, None, **draw_params_good)\n","mfilt_image_bad = cv2.drawMatchesKnn(img1, kp1, img2, kp2, bad, None, **draw_params_bad)\n","pts1 = np.float32(pts1)\n","pts2 = np.float32(pts2)\n","print('Nb de paires sélectionnées : ' + str(pts1.shape[0]))\n","\n","plt.figure(figsize=(15, 5))\n","plt.subplot(121), plt.imshow(mfilt_image_good)\n","plt.title('Appariement filtré (bons) : %i paires conservées' % len(good))\n","plt.subplot(122), plt.imshow(mfilt_image_bad)\n","plt.title('Appariement filtré (mauvais) : %i paires conservées' % len(bad))\n","plt.show()\n","\n","##### Définition des fonctions auxiliaires\n","def drawlines(img1, img2, lines, pts1, pts2):\n","    ''' img1 - image sur laquelle on dessine les épilines pour les points dans img2\n","        lines - épilines correspondantes '''\n","    r, c = img1.shape\n","    img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n","    img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n","    for r, pt1, pt2 in zip(lines, pts1, pts2):\n","        color = tuple(cv2.cvtColor(np.asarray([[[np.random.randint(0, 180), 255, 255]]], dtype=np.uint8), cv2.COLOR_HSV2BGR)[0, 0, :].tolist())\n","        x0, y0 = map(int, [0, -r[2] / r[1]])\n","        x1, y1 = map(int, [c, -(r[2] + r[0] * c) / r[1]])\n","        img1 = cv2.line(img1, (x0, y0), (x1, y1), color, 2)\n","        img1 = cv2.circle(img1, (int(pt1[0]), int(pt1[1])), 5, color, -1)\n","        img2 = cv2.circle(img2, (int(pt2[0]), int(pt2[1])), 5, color, -1)\n","    return img1, img2\n","\n","def drawFundamental(img1, img2, pts1, pts2, F):\n","    # Trouver les épilines correspondant à certains points de l'image de droite (deuxième image)\n","    # et dessiner leurs lignes sur l'image de gauche\n","    indexes = np.random.randint(0, pts1.shape[0], size=(10))\n","    indexes = range(pts1.shape[0])\n","    samplePt1 = pts1[indexes, :]\n","    samplePt2 = pts2[indexes, :]\n","\n","    lines1 = cv2.computeCorrespondEpilines(samplePt2.reshape(-1, 1, 2), 2, F)\n","    lines1 = lines1.reshape(-1, 3)\n","    img5, img6 = drawlines(img1, img2, lines1, samplePt1, samplePt2)\n","\n","    # Trouver les épilines correspondant à certains points de l'image de gauche (première image)\n","    # et dessiner leurs lignes sur l'image de droite\n","\n","    lines2 = cv2.computeCorrespondEpilines(samplePt1.reshape(-1, 1, 2), 1, F)\n","    lines2 = lines2.reshape(-1, 3)\n","    img3, img4 = drawlines(img2, img1, lines2, samplePt2, samplePt1)\n","    return img5, img3\n","\n","###### Calcul de la Matrice Fondamentale avec OpenCV RANSAC\n","FRansac, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC,\n","                                       ransacReprojThreshold=0.99,  # Distance max de reprojection en pixels pour un inlier\n","                                       confidence=0.99)  # Niveau de confiance désiré\n","print('Nb inliers RANSAC : ' + str(mask.sum()))\n","\n","# Affichage des inliers uniquement\n","inlierpts1 = pts1[mask.ravel() == 1]\n","inlierpts2 = pts2[mask.ravel() == 1]\n","\n","# Tracer les droites épipolaires\n","imgL, imgR = drawFundamental(img1, img2, inlierpts1, inlierpts2, FRansac)\n","plt.figure(figsize=(15, 5))\n","plt.subplot(121), plt.imshow(imgL)\n","plt.title('Lignes épipolaires des %i inliers (gauche)' % mask.sum())\n","plt.subplot(122), plt.imshow(imgR)\n","plt.title('Lignes épipolaires des %i inliers (droite)' % mask.sum())\n","plt.show()\n"],"metadata":{"id":"KLtsqzezgd1y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","###### Lecture des deux images\n","# input1 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/obj_left.png') # image de droite\n","# input2 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/obj_right.png') # image de gauche\n","input1 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imLeft.png') # image de droite\n","input2 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imRight.png') # image de gauche\n","# Conversion en niveaux de gris\n","img1 = cv2.cvtColor(input1, cv2.COLOR_BGR2GRAY)\n","img2 = cv2.cvtColor(input2, cv2.COLOR_BGR2GRAY)\n","\n","###### Détection des points clefs\n","kaze = cv2.KAZE_create()\n","\n","# Détection des points KAZE et calcul des descripteurs M-SURF\n","kp1, des1 = kaze.detectAndCompute(img1, None)\n","kp2, des2 = kaze.detectAndCompute(img2, None)\n","\n","print('Nb de SIFT : ' + str(len(kp1)) + ' (gauche) ' + str(len(kp2)) + ' (droite)')\n","imgd = cv2.drawKeypoints(img1, kp1, None, -1, flags=cv2.DrawMatchesFlags_DEFAULT)\n","plt.imshow(imgd), plt.title('%i Points SIFT (Image de gauche)' % len(kp1))\n","plt.show()\n","\n","pts1 = []\n","pts2 = []\n","\n","# Distance L2 pour descripteur M-SURF (KAZE)\n","bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n","# Extraction de la liste des 2-plus-proches-voisins\n","matches = bf.knnMatch(des1, des2, k=2)\n","# Filtrage des appariements par application du ratio test\n","good = []\n","for m, n in matches:\n","    if m.distance < 0.75 * n.distance:\n","        pts2.append(kp2[m.trainIdx].pt)\n","        pts1.append(kp1[m.queryIdx].pt)\n","        good.append([m])\n","\n","mfilt_image = np.array([])\n","draw_params = dict(matchColor=(0, 255, 0),\n","                   singlePointColor=(255, 0, 0),\n","                   flags=0)\n","mfilt_image = cv2.drawMatchesKnn(img1, kp1, img2, kp2, good, None, **draw_params)\n","pts1 = np.float32(pts1)\n","pts2 = np.float32(pts2)\n","print('Nb de paires sélectionnées : ' + str(pts1.shape[0]))\n","\n","plt.figure(figsize=(15, 5))\n","plt.imshow(mfilt_image)\n","plt.title('Appariement filtré : %i paires conservées' % pts1.shape[0])\n","plt.show()\n","\n","##### Définition des fonctions auxiliaires\n","def drawlines(img1, img2, lines, pts1, pts2):\n","    ''' img1 - image sur laquelle on dessine les épilines pour les points dans img2\n","        lines - épilines correspondantes '''\n","    r, c = img1.shape\n","    img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n","    img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n","    for r, pt1, pt2 in zip(lines, pts1, pts2):\n","        color = tuple(cv2.cvtColor(np.asarray([[[np.random.randint(0, 180), 255, 255]]], dtype=np.uint8), cv2.COLOR_HSV2BGR)[0, 0, :].tolist())\n","        x0, y0 = map(int, [0, -r[2] / r[1]])\n","        x1, y1 = map(int, [c, -(r[2] + r[0] * c) / r[1]])\n","        img1 = cv2.line(img1, (x0, y0), (x1, y1), color, 2)\n","        img1 = cv2.circle(img1, (int(pt1[0]), int(pt1[1])), 5, color, -1)\n","        img2 = cv2.circle(img2, (int(pt2[0]), int(pt2[1])), 5, color, -1)\n","    return img1, img2\n","\n","def drawFundamental(img1, img2, pts1, pts2, F):\n","    # Trouver les épilines correspondant à certains points de l'image de droite (deuxième image)\n","    # et dessiner leurs lignes sur l'image de gauche\n","    indexes = np.random.randint(0, pts1.shape[0], size=(10))\n","    indexes = range(pts1.shape[0])\n","    samplePt1 = pts1[indexes, :]\n","    samplePt2 = pts2[indexes, :]\n","\n","    lines1 = cv2.computeCorrespondEpilines(samplePt2.reshape(-1, 1, 2), 2, F)\n","    lines1 = lines1.reshape(-1, 3)\n","    img5, img6 = drawlines(img1, img2, lines1, samplePt1, samplePt2)\n","\n","    # Trouver les épilines correspondant à certains points de l'image de gauche (première image)\n","    # et dessiner leurs lignes sur l'image de droite\n","\n","    lines2 = cv2.computeCorrespondEpilines(samplePt1.reshape(-1, 1, 2), 1, F)\n","    lines2 = lines2.reshape(-1, 3)\n","    img3, img4 = drawlines(img2, img1, lines2, samplePt2, samplePt1)\n","    return img5, img3\n","\n","###### Calcul de la Matrice Fondamentale avec OpenCV RANSAC\n","FRansac, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC,\n","                                       ransacReprojThreshold=0.99,  # Distance max de reprojection en pixels pour un inlier\n","                                       confidence=0.99)  # Niveau de confiance désiré\n","print('Nb inliers RANSAC : ' + str(mask.sum()))\n","\n","# Affichage des inliers uniquement\n","inlierpts1 = pts1[mask.ravel() == 1]\n","inlierpts2 = pts2[mask.ravel() == 1]\n","\n","# Tracer les droites épipolaires\n","imgL, imgR = drawFundamental(img1, img2, inlierpts1, inlierpts2, FRansac)\n","plt.figure(figsize=(15, 5))\n","plt.subplot(121), plt.imshow(imgL)\n","plt.title('Lignes épipolaires des %i inliers (gauche)' % mask.sum())\n","plt.subplot(122), plt.imshow(imgR)\n","plt.title('Lignes épipolaires des %i inliers (droite)' % mask.sum())\n","plt.show()\n"],"metadata":{"id":"XxecgSiufDJ7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","###### Lecture des deux images\n","# input1 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/obj_left.png') # image de droite\n","# input2 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/obj_right.png') # image de gauche\n","input1 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imLeft.png') # image de droite\n","input2 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imRight.png') # image de gauche\n","# Conversion en niveaux de gris\n","img1 = cv2.cvtColor(input1, cv2.COLOR_BGR2GRAY)\n","img2 = cv2.cvtColor(input2, cv2.COLOR_BGR2GRAY)\n","\n","###### Détection des points clefs\n","kaze = cv2.KAZE_create()\n","\n","# Détection des points KAZE et calcul des descripteurs M-SURF\n","kp1, des1 = kaze.detectAndCompute(img1, None)\n","kp2, des2 = kaze.detectAndCompute(img2, None)\n","\n","print('Nb de SIFT : ' + str(len(kp1)) + ' (gauche) ' + str(len(kp2)) + ' (droite)')\n","imgd = cv2.drawKeypoints(img1, kp1, None, -1, flags=cv2.DrawMatchesFlags_DEFAULT)\n","plt.imshow(imgd), plt.title('%i Points SIFT (Image de gauche)' % len(kp1))\n","plt.show()\n","\n","pts1 = []\n","pts2 = []\n","\n","# Distance L2 pour descripteur M-SURF (KAZE)\n","bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n","# Extraction de la liste des 2-plus-proches-voisins\n","matches = bf.knnMatch(des1, des2, k=2)\n","# Filtrage des appariements par application du ratio test\n","good = []\n","for m, n in matches:\n","    if m.distance < 0.1 * n.distance:\n","        pts2.append(kp2[m.trainIdx].pt)\n","        pts1.append(kp1[m.queryIdx].pt)\n","        good.append([m])\n","\n","mfilt_image = np.array([])\n","draw_params = dict(matchColor=(0, 255, 0),\n","                   singlePointColor=(255, 0, 0),\n","                   flags=0)\n","mfilt_image = cv2.drawMatchesKnn(img1, kp1, img2, kp2, good, None, **draw_params)\n","pts1 = np.float32(pts1)\n","pts2 = np.float32(pts2)\n","print('Nb de paires sélectionnées : ' + str(pts1.shape[0]))\n","\n","plt.figure(figsize=(15, 5))\n","plt.imshow(mfilt_image)\n","plt.title('Appariement filtré : %i paires conservées' % pts1.shape[0])\n","plt.show()\n","\n","##### Définition des fonctions auxiliaires\n","def drawlines(img1, img2, lines, pts1, pts2):\n","    ''' img1 - image sur laquelle on dessine les épilines pour les points dans img2\n","        lines - épilines correspondantes '''\n","    r, c = img1.shape\n","    img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n","    img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n","    for r, pt1, pt2 in zip(lines, pts1, pts2):\n","        color = tuple(cv2.cvtColor(np.asarray([[[np.random.randint(0, 180), 255, 255]]], dtype=np.uint8), cv2.COLOR_HSV2BGR)[0, 0, :].tolist())\n","        x0, y0 = map(int, [0, -r[2] / r[1]])\n","        x1, y1 = map(int, [c, -(r[2] + r[0] * c) / r[1]])\n","        img1 = cv2.line(img1, (x0, y0), (x1, y1), color, 2)\n","        img1 = cv2.circle(img1, (int(pt1[0]), int(pt1[1])), 5, color, -1)\n","        img2 = cv2.circle(img2, (int(pt2[0]), int(pt2[1])), 5, color, -1)\n","    return img1, img2\n","\n","def drawFundamental(img1, img2, pts1, pts2, F):\n","    # Trouver les épilines correspondant à certains points de l'image de droite (deuxième image)\n","    # et dessiner leurs lignes sur l'image de gauche\n","    indexes = np.random.randint(0, pts1.shape[0], size=(10))\n","    indexes = range(pts1.shape[0])\n","    samplePt1 = pts1[indexes, :]\n","    samplePt2 = pts2[indexes, :]\n","\n","    lines1 = cv2.computeCorrespondEpilines(samplePt2.reshape(-1, 1, 2), 2, F)\n","    lines1 = lines1.reshape(-1, 3)\n","    img5, img6 = drawlines(img1, img2, lines1, samplePt1, samplePt2)\n","\n","    # Trouver les épilines correspondant à certains points de l'image de gauche (première image)\n","    # et dessiner leurs lignes sur l'image de droite\n","\n","    lines2 = cv2.computeCorrespondEpilines(samplePt1.reshape(-1, 1, 2), 1, F)\n","    lines2 = lines2.reshape(-1, 3)\n","    img3, img4 = drawlines(img2, img1, lines2, samplePt2, samplePt1)\n","    return img5, img3\n","\n","###### Calcul de la Matrice Fondamentale avec OpenCV RANSAC\n","FRansac, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC,\n","                                       ransacReprojThreshold=0.99,  # Distance max de reprojection en pixels pour un inlier\n","                                       confidence=0.99)  # Niveau de confiance désiré\n","print('Nb inliers RANSAC : ' + str(mask.sum()))\n","\n","# Affichage des inliers uniquement\n","inlierpts1 = pts1[mask.ravel() == 1]\n","inlierpts2 = pts2[mask.ravel() == 1]\n","\n","# Tracer les droites épipolaires\n","imgL, imgR = drawFundamental(img1, img2, inlierpts1, inlierpts2, FRansac)\n","plt.figure(figsize=(15, 5))\n","plt.subplot(121), plt.imshow(imgL)\n","plt.title('Lignes épipolaires des %i inliers (gauche)' % mask.sum())\n","plt.subplot(122), plt.imshow(imgR)\n","plt.title('Lignes épipolaires des %i inliers (droite)' % mask.sum())\n","plt.show()\n"],"metadata":{"id":"OgoxFNaVW2oQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import os\n","from google.colab.patches import cv2_imshow\n","import matplotlib.pyplot as plt\n","\n","def load_images(left_image_path, right_image_path):\n","    if not os.path.exists(left_image_path):\n","        raise FileNotFoundError(f\"Left image not found at {left_image_path}\")\n","    if not os.path.exists(right_image_path):\n","        raise FileNotFoundError(f\"Right image not found at {right_image_path}\")\n","\n","    img_left = cv2.imread(left_image_path, cv2.IMREAD_GRAYSCALE)\n","    img_right = cv2.imread(right_image_path, cv2.IMREAD_GRAYSCALE)\n","\n","    if img_left is None or img_right is None:\n","        raise FileNotFoundError(\"One of the images was not found or could not be loaded.\")\n","\n","    return img_left, img_right\n","\n","def detect_sift_features(image):\n","    sift = cv2.SIFT_create()\n","    keypoints, descriptors = sift.detectAndCompute(image, None)\n","    if keypoints is None or descriptors is None:\n","        raise ValueError(\"No keypoints or descriptors found in the image.\")\n","    return keypoints, descriptors\n","\n","def match_features(descriptors_left, descriptors_right):\n","    index_params = dict(algorithm=1, trees=5)\n","    search_params = dict(checks=50)\n","    flann = cv2.FlannBasedMatcher(index_params, search_params)\n","    matches = flann.knnMatch(descriptors_left, descriptors_right, k=2)\n","    good_matches = []\n","    for m, n in matches:\n","        if m.distance < 0.75 * n.distance:\n","            good_matches.append(m)\n","    return good_matches\n","\n","def draw_matches(img_left, img_right, keypoints_left, keypoints_right, good_matches):\n","    img_matches = cv2.drawMatches(img_left, keypoints_left, img_right, keypoints_right, good_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n","    return img_matches\n","\n","def compute_disparity_map(img_left, img_right):\n","    stereo = cv2.StereoBM_create(numDisparities=16, blockSize=15)\n","    disparity = stereo.compute(img_left, img_right)\n","    return disparity\n","\n","def main():\n","    left_image_path = '/content/drive/MyDrive/COMPUTER_VISION/obj_left.png'\n","    right_image_path = '/content/drive/MyDrive/COMPUTER_VISION/obj_right.png'\n","\n","    img_left, img_right = load_images(left_image_path, right_image_path)\n","\n","    keypoints_left, descriptors_left = detect_sift_features(img_left)\n","    keypoints_right, descriptors_right = detect_sift_features(img_right)\n","\n","    good_matches = match_features(descriptors_left, descriptors_right)\n","\n","    img_matches = draw_matches(img_left, img_right, keypoints_left, keypoints_right, good_matches)\n","\n","    disparity = compute_disparity_map(img_left, img_right)\n","    disp_norm = cv2.normalize(disparity, None, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n","    disp_norm = np.uint8(disp_norm)\n","\n","    # Affichage des résultats avec matplotlib\n","    plt.figure(figsize=(15, 5))\n","\n","    plt.subplot(1, 3, 1)\n","    plt.imshow(img_left, cmap='gray')\n","    plt.title('Image I(x,y)')\n","\n","    plt.subplot(1, 3, 2)\n","    plt.imshow(disp_norm, cmap='gray')\n","    plt.title('Carte des disparités D(x,y)')\n","\n","    plt.subplot(1, 3, 3)\n","    plt.imshow(img_right, cmap='gray')\n","    plt.title(\"Image I'(x', y')\")\n","\n","    plt.show()\n","\n","if __name__ == '__main__':\n","    main()\n"],"metadata":{"id":"n7GNROYe2WMG"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import os\n","from matplotlib import pyplot as plt\n","\n","def load_images(left_image_path, right_image_path):\n","    if not os.path.exists(left_image_path):\n","        raise FileNotFoundError(f\"Left image not found at {left_image_path}\")\n","    if not os.path.exists(right_image_path):\n","        raise FileNotFoundError(f\"Right image not found at {right_image_path}\")\n","\n","    img_left = cv2.imread(left_image_path, cv2.IMREAD_GRAYSCALE)\n","    img_right = cv2.imread(right_image_path, cv2.IMREAD_GRAYSCALE)\n","\n","    if img_left is None or img_right is None:\n","        raise FileNotFoundError(\"One of the images was not found or could not be loaded.\")\n","\n","    return img_left, img_right\n","\n","def detect_sift_features(image):\n","    sift = cv2.SIFT_create()\n","    keypoints, descriptors = sift.detectAndCompute(image, None)\n","    if keypoints is None or descriptors is None:\n","        raise ValueError(\"No keypoints or descriptors found in the image.\")\n","    return keypoints, descriptors\n","\n","def match_features(descriptors_left, descriptors_right):\n","    index_params = dict(algorithm=1, trees=5)\n","    search_params = dict(checks=30)\n","    flann = cv2.FlannBasedMatcher(index_params, search_params)\n","    matches = flann.knnMatch(descriptors_left, descriptors_right, k=2)\n","    good_matches = []\n","    for m, n in matches:\n","        if m.distance < 0.99 * n.distance:\n","            good_matches.append(m)\n","    return good_matches\n","\n","def filter_matches_ransac(good_matches, keypoints_left, keypoints_right):\n","    if len(good_matches) > 4:\n","        src_pts = np.float32([keypoints_left[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n","        dst_pts = np.float32([keypoints_right[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n","\n","        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n","        matches_mask = mask.ravel().tolist()\n","\n","        ransac_matches = [good_matches[i] for i in range(len(good_matches)) if matches_mask[i]]\n","\n","        return ransac_matches\n","    else:\n","        return []\n","\n","def draw_matches(img_left, img_right, keypoints_left, keypoints_right, matches, matches_title):\n","    img_matches = cv2.drawMatches(img_left, keypoints_left, img_right, keypoints_right, matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n","\n","    plt.figure(figsize=(10, 5))\n","    plt.imshow(img_matches)\n","    plt.title(matches_title)\n","    plt.axis('off')\n","    plt.show()\n","\n","def main():\n","    left_image_path = '/content/drive/MyDrive/COMPUTER_VISION/Left_img.PNG'\n","    right_image_path = '/content/drive/MyDrive/COMPUTER_VISION/Right_img.PNG'  # Utilise les chemins d'accès corrects pour tes images\n","\n","    img_left, img_right = load_images(left_image_path, right_image_path)\n","\n","    keypoints_left, descriptors_left = detect_sift_features(img_left)\n","    keypoints_right, descriptors_right = detect_sift_features(img_right)\n","\n","    good_matches = match_features(descriptors_left, descriptors_right)\n","\n","    # Filtrage avec RANSAC\n","    ransac_matches = filter_matches_ransac(good_matches, keypoints_left, keypoints_right)\n","\n","    # Affichage des correspondances avant et après RANSAC\n","    draw_matches(img_left, img_right, keypoints_left, keypoints_right, good_matches, 'Correspondances initiales')\n","    draw_matches(img_left, img_right, keypoints_left, keypoints_right, ransac_matches, 'Correspondances filtrées par RANSAC')\n","\n","if __name__ == '__main__':\n","    main()\n"],"metadata":{"id":"JTDYRsoMEwp1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import os\n","from matplotlib import pyplot as plt\n","\n","def load_images(left_image_path, right_image_path):\n","    if not os.path.exists(left_image_path):\n","        raise FileNotFoundError(f\"Left image not found at {left_image_path}\")\n","    if not os.path.exists(right_image_path):\n","        raise FileNotFoundError(f\"Right image not found at {right_image_path}\")\n","\n","    img_left = cv2.imread(left_image_path, cv2.IMREAD_GRAYSCALE)\n","    img_right = cv2.imread(right_image_path, cv2.IMREAD_GRAYSCALE)\n","\n","    if img_left is None or img_right is None:\n","        raise FileNotFoundError(\"One of the images was not found or could not be loaded.\")\n","\n","    return img_left, img_right\n","\n","def detect_sift_features(image):\n","    sift = cv2.SIFT_create()\n","    keypoints, descriptors = sift.detectAndCompute(image, None)\n","    if keypoints is None or descriptors is None:\n","        raise ValueError(\"No keypoints or descriptors found in the image.\")\n","    return keypoints, descriptors\n","\n","def match_features(descriptors_left, descriptors_right):\n","    index_params = dict(algorithm=1, trees=5)\n","    search_params = dict(checks=30)\n","    flann = cv2.FlannBasedMatcher(index_params, search_params)\n","    matches = flann.knnMatch(descriptors_left, descriptors_right, k=2)\n","    good_matches = []\n","    for m, n in matches:\n","        if m.distance < 0.10 * n.distance:\n","            good_matches.append(m)\n","    return good_matches\n","\n","def filter_matches_ransac(good_matches, keypoints_left, keypoints_right):\n","    if len(good_matches) > 5:\n","        src_pts = np.float32([keypoints_left[m.queryIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n","        dst_pts = np.float32([keypoints_right[m.trainIdx].pt for m in good_matches]).reshape(-1, 1, 2)\n","\n","        M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 5.0)\n","        matches_mask = mask.ravel().tolist()\n","\n","        ransac_matches = [good_matches[i] for i in range(len(good_matches)) if matches_mask[i]]\n","\n","        return ransac_matches, M\n","    else:\n","        return [], None\n","\n","def draw_matches_custom(img_left, img_right, keypoints_left, keypoints_right, matches, matches_title):\n","    # Create a combined image\n","    h1, w1 = img_left.shape\n","    h2, w2 = img_right.shape\n","    combined_img = np.zeros((h1 + h2, max(w1, w2), 3), dtype='uint8')\n","    combined_img[:h1, :w1] = cv2.cvtColor(img_left, cv2.COLOR_GRAY2BGR)\n","    combined_img[h1:h1 + h2, :w2] = cv2.cvtColor(img_right, cv2.COLOR_GRAY2BGR)\n","\n","    for match in matches:\n","        pt1 = (int(keypoints_left[match.queryIdx].pt[0]), int(keypoints_left[match.queryIdx].pt[1]))\n","        pt2 = (int(keypoints_right[match.trainIdx].pt[0]), int(keypoints_right[match.trainIdx].pt[1] + h1))\n","\n","        cv2.circle(combined_img, pt1, 3, (0, 255, 0), -1)\n","        cv2.circle(combined_img, pt2, 3, (0, 255, 0), -1)\n","        cv2.line(combined_img, pt1, pt2, (0, 0, 255), 1)\n","\n","    plt.imshow(combined_img)\n","    plt.title(matches_title)\n","    plt.axis('off')\n","    plt.show()\n","\n","def main():\n","    left_image_path = '/content/drive/MyDrive/COMPUTER_VISION/imLeft.png'\n","    right_image_path = '/content/drive/MyDrive/COMPUTER_VISION/imRight.png'\n","\n","    img_left, img_right = load_images(left_image_path, right_image_path)\n","\n","    keypoints_left, descriptors_left = detect_sift_features(img_left)\n","    keypoints_right, descriptors_right = detect_sift_features(img_right)\n","\n","    good_matches = match_features(descriptors_left, descriptors_right)\n","\n","    # Filtrage avec RANSAC\n","    ransac_matches, H = filter_matches_ransac(good_matches, keypoints_left, keypoints_right)\n","\n","    # Transformation de l'image gauche pour ressembler à l'image droite\n","    height, width = img_right.shape\n","    img_left_warp = cv2.warpPerspective(img_left, H, (width, height))\n","\n","    # Affichage des correspondances avant et après RANSAC dans une disposition verticale\n","    fig, axs = plt.subplots(4, 1, figsize=(10, 20))\n","\n","    axs[0].imshow(cv2.cvtColor(img_left, cv2.COLOR_GRAY2BGR))\n","    axs[0].set_title('Image Gauche')\n","    axs[0].axis('off')\n","\n","    axs[1].imshow(cv2.cvtColor(img_right, cv2.COLOR_GRAY2BGR))\n","    axs[1].set_title('Image Droite')\n","    axs[1].axis('off')\n","\n","    draw_matches_custom(img_left, img_right, keypoints_left, keypoints_right, good_matches, 'Correspondances Initiales')\n","    draw_matches_custom(img_left, img_right, keypoints_left, keypoints_right, ransac_matches, 'Correspondances Filtrées par RANSAC')\n","\n","    plt.show()\n","\n","    plt.figure(figsize=(10, 10))\n","    plt.imshow(cv2.cvtColor(img_left_warp, cv2.COLOR_GRAY2BGR))\n","    plt.title(\"Transformation de l'image gauche pour ressembler à la droite\")\n","    plt.axis('off')\n","    plt.show()\n","\n","if __name__ == '__main__':\n","    main()\n"],"metadata":{"id":"ELvBR-kMKwHt"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy.spatial.distance import cdist\n"],"metadata":{"id":"WL6wD8QQfWMe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Chargement et affichage des images**"],"metadata":{"id":"YhDW8CTbfekR"}},{"cell_type":"code","source":["# Charger les images stéréoscopiques\n","# img_left = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/POP01.jpg', cv2.IMREAD_GRAYSCALE)\n","# img_right = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/POP02.jpg', cv2.IMREAD_GRAYSCALE)\n","img_left = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imLeft.png', cv2.IMREAD_GRAYSCALE)\n","img_right = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imRight.png', cv2.IMREAD_GRAYSCALE)\n","\n","# Affichage des images\n","plt.figure(figsize=(10, 5))\n","plt.subplot(1, 2, 1)\n","plt.title(\"Image Gauche\")\n","plt.imshow(img_left, cmap='gray')\n","plt.subplot(1, 2, 2)\n","plt.title(\"Image Droite\")\n","plt.imshow(img_right, cmap='gray')\n","plt.show()\n"],"metadata":{"id":"mnpvfDaLff_F"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Détection des points SIFT et correspondance des points**"],"metadata":{"id":"oYAbNMLlflMt"}},{"cell_type":"code","source":["# Création du détecteur SIFT\n","sift = cv2.SIFT_create()\n","\n","# Détection des points d'intérêt SIFT\n","keypoints_left, descriptors_left = sift.detectAndCompute(img_left, None)\n","keypoints_right, descriptors_right = sift.detectAndCompute(img_right, None)\n","\n","# Correspondance des points d'intérêt avec le matcher BFMatcher\n","bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n","matches = bf.match(descriptors_left, descriptors_right)\n","\n","# Tri des correspondances par distance\n","matches = sorted(matches, key=lambda x: x.distance)\n","\n","# Affichage des 10 meilleures correspondances\n","img_matches = cv2.drawMatches(img_left, keypoints_left, img_right, keypoints_right, matches[:650], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n","plt.figure(figsize=(15, 10))\n","plt.title(\"Correspondances SIFT\")\n","plt.imshow(img_matches)\n","plt.show()\n"],"metadata":{"id":"PPAggP0xfnSv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Affinement des correspondances avec RANSAC**"],"metadata":{"id":"IlcsYGGBft_V"}},{"cell_type":"code","source":["# Extraction des points de correspondance\n","pts_left = np.float32([keypoints_left[m.queryIdx].pt for m in matches])\n","pts_right = np.float32([keypoints_right[m.trainIdx].pt for m in matches])\n","\n","# Utilisation de RANSAC pour affiner les correspondances\n","H, mask = cv2.findHomography(pts_left, pts_right, cv2.RANSAC, 7.5)\n","matchesMask = mask.ravel().tolist()\n","\n","# Affichage des correspondances après RANSAC\n","img_ransac_matches = cv2.drawMatches(img_left, keypoints_left, img_right, keypoints_right, [m for i, m in enumerate(matches) if matchesMask[i]], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n","plt.figure(figsize=(15, 10))\n","plt.title(\"Correspondances SIFT après RANSAC\")\n","plt.imshow(img_ransac_matches)\n","plt.show()\n"],"metadata":{"id":"ydVyBzjHfpfl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install opencv-python opencv-contrib-python matplotlib numpy"],"metadata":{"id":"5wv-DmashtDo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# **Calcul de la carte de disparité**"],"metadata":{"id":"lP-ePtqVfzBd"}},{"cell_type":"code","source":["\n","# Importation des bibliothèques nécessaires\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from scipy.spatial.distance import cdist\n","\n","# Charger les images stéréoscopiques\n","# img_left = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/shed_left.png', cv2.IMREAD_GRAYSCALE)\n","# img_right = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/shed_right.png', cv2.IMREAD_GRAYSCALE)\n","img_left = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imLeft.png', cv2.IMREAD_GRAYSCALE)\n","img_right = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imRight.png', cv2.IMREAD_GRAYSCALE)\n","\n","# Assurez-vous que les deux images ont la même taille\n","height, width = img_left.shape\n","if img_right.shape != img_left.shape:\n","    img_right = cv2.resize(img_right, (width, height))\n","\n","# Affichage des images\n","plt.figure(figsize=(10, 5))\n","plt.subplot(1, 2, 1)\n","plt.title(\"Image Gauche\")\n","plt.imshow(img_left, cmap='gray')\n","plt.subplot(1, 2, 2)\n","plt.title(\"Image Droite\")\n","plt.imshow(img_right, cmap='gray')\n","plt.show()\n","\n","# Création du détecteur SIFT\n","sift = cv2.SIFT_create()\n","\n","# Détection des points d'intérêt SIFT\n","keypoints_left, descriptors_left = sift.detectAndCompute(img_left, None)\n","keypoints_right, descriptors_right = sift.detectAndCompute(img_right, None)\n","\n","# Correspondance des points d'intérêt avec le matcher BFMatcher\n","bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n","matches = bf.match(descriptors_left, descriptors_right)\n","\n","# Tri des correspondances par distance\n","matches = sorted(matches, key=lambda x: x.distance)\n","\n","# Affichage des 10 meilleures correspondances\n","img_matches = cv2.drawMatches(img_left, keypoints_left, img_right, keypoints_right, matches[:50], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n","plt.figure(figsize=(15, 10))\n","plt.title(\"Correspondances SIFT\")\n","plt.imshow(img_matches)\n","plt.show()\n","\n","# Extraction des points de correspondance\n","pts_left = np.float32([keypoints_left[m.queryIdx].pt for m in matches])\n","pts_right = np.float32([keypoints_right[m.trainIdx].pt for m in matches])\n","\n","# Utilisation de RANSAC pour affiner les correspondances\n","H, mask = cv2.findHomography(pts_left, pts_right, cv2.RANSAC, 1.0)\n","matchesMask = mask.ravel().tolist()\n","\n","# Affichage des correspondances après RANSAC\n","img_ransac_matches = cv2.drawMatches(img_left, keypoints_left, img_right, keypoints_right, [m for i, m in enumerate(matches) if matchesMask[i]], None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n","plt.figure(figsize=(15, 10))\n","plt.title(\"Correspondances SIFT après RANSAC\")\n","plt.imshow(img_ransac_matches)\n","plt.show()\n","\n","# Calcul de la carte de disparité\n","stereo = cv2.StereoBM_create(numDisparities=16, blockSize=15)\n","disparity = stereo.compute(img_left, img_right)\n","\n","# Affichage de la carte de disparité\n","plt.figure(figsize=(10, 5))\n","plt.title(\"Carte de Disparité\")\n","plt.imshow(disparity, 'gray')\n","plt.show()\n","\n","# Calcul de la matrice fondamentale\n","F, mask = cv2.findFundamentalMat(pts_left, pts_right, cv2.FM_RANSAC)\n","\n","# Sélection des points inliers\n","pts_left_inliers = pts_left[mask.ravel() == 1]\n","pts_right_inliers = pts_right[mask.ravel() == 1]\n","\n","# Calcul des lignes épipolaires pour les points inliers\n","lines_left = cv2.computeCorrespondEpilines(pts_right_inliers.reshape(-1, 1, 2), 2, F)\n","lines_left = lines_left.reshape(-1, 3)\n","\n","lines_right = cv2.computeCorrespondEpilines(pts_left_inliers.reshape(-1, 1, 2), 1, F)\n","lines_right = lines_right.reshape(-1, 3)\n","\n","def draw_epilines(img1, img2, lines, pts1, pts2):\n","    ''' Fonction pour dessiner les lignes épipolaires '''\n","    r, c = img1.shape\n","    img1_color = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n","    img2_color = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n","\n","    for r, pt1, pt2 in zip(lines, pts1, pts2):\n","        color = tuple(np.random.randint(0, 255, 3).tolist())\n","        x0, y0 = map(int, [0, -r[2]/r[1]])\n","        x1, y1 = map(int, [c, -(r[2]+r[0]*c)/r[1]])\n","        img1_color = cv2.line(img1_color, (x0, y0), (x1, y1), (0, 255, 0), 1)\n","        img1_color = cv2.circle(img1_color, (int(pt1[0]), int(pt1[1])), 5, color, -1)\n","        img2_color = cv2.circle(img2_color, (int(pt2[0]), int(pt2[1])), 5, color, -1)\n","    return img1_color, img2_color\n","\n","# Dessiner les lignes épipolaires sur les images\n","img_left_epilines, img_right_epilines = draw_epilines(img_left, img_right, lines_left, pts_left_inliers, pts_right_inliers)\n","img_right_epilines, img_left_epilines = draw_epilines(img_right, img_left, lines_right, pts_right_inliers, pts_left_inliers)\n","\n","# Affichage des images avec les lignes épipolaires\n","plt.figure(figsize=(15, 10))\n","plt.subplot(1, 2, 1)\n","plt.title(\"Lignes épipolaires sur l'image gauche\")\n","plt.imshow(img_left_epilines)\n","plt.subplot(1, 2, 2)\n","plt.title(\"Lignes épipolaires sur l'image droite\")\n","plt.imshow(img_right_epilines)\n","plt.show()\n"],"metadata":{"id":"HD3qdGorf0hU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","###### Lecture des deux images\n","# input1 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/obj_left.png') # image de droite\n","# input2 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/obj_right.png') # image de gauche\n","input1 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imLeft.png') # image de droite\n","input2 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imRight.png') # image de gauche\n","# Conversion en niveaux de gris\n","img1 = cv2.cvtColor(input1, cv2.COLOR_BGR2GRAY)\n","img2 = cv2.cvtColor(input2, cv2.COLOR_BGR2GRAY)\n","\n","###### Détection des points clefs\n","kaze = cv2.KAZE_create()\n","\n","# Détection des points KAZE et calcul des descripteurs M-SURF\n","kp1, des1 = kaze.detectAndCompute(img1, None)\n","kp2, des2 = kaze.detectAndCompute(img2, None)\n","\n","print('Nb de SIFT : ' + str(len(kp1)) + ' (gauche) ' + str(len(kp2)) + ' (droite)')\n","imgd = cv2.drawKeypoints(img1, kp1, None, -1, flags=cv2.DrawMatchesFlags_DEFAULT)\n","plt.imshow(imgd), plt.title('%i Points SIFT (Image de gauche)' % len(kp1))\n","plt.show()\n","\n","pts1 = []\n","pts2 = []\n","\n","# Distance L2 pour descripteur M-SURF (KAZE)\n","bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n","# Extraction de la liste des 2-plus-proches-voisins\n","matches = bf.knnMatch(des1, des2, k=2)\n","# Filtrage des appariements par application du ratio test\n","good = []\n","for m, n in matches:\n","    if m.distance < 0.1 * n.distance:\n","        pts2.append(kp2[m.trainIdx].pt)\n","        pts1.append(kp1[m.queryIdx].pt)\n","        good.append([m])\n","\n","mfilt_image = np.array([])\n","draw_params = dict(matchColor=(0, 255, 0),\n","                   singlePointColor=(255, 0, 0),\n","                   flags=0)\n","mfilt_image = cv2.drawMatchesKnn(img1, kp1, img2, kp2, good, None, **draw_params)\n","pts1 = np.float32(pts1)\n","pts2 = np.float32(pts2)\n","print('Nb de paires sélectionnées : ' + str(pts1.shape[0]))\n","\n","plt.figure(figsize=(15, 5))\n","plt.imshow(mfilt_image)\n","plt.title('Appariement filtré : %i paires conservées' % pts1.shape[0])\n","plt.show()\n","\n","##### Définition des fonctions auxiliaires\n","def drawlines(img1, img2, lines, pts1, pts2):\n","    ''' img1 - image sur laquelle on dessine les épilines pour les points dans img2\n","        lines - épilines correspondantes '''\n","    r, c = img1.shape\n","    img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n","    img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n","    for r, pt1, pt2 in zip(lines, pts1, pts2):\n","        color = tuple(cv2.cvtColor(np.asarray([[[np.random.randint(0, 180), 255, 255]]], dtype=np.uint8), cv2.COLOR_HSV2BGR)[0, 0, :].tolist())\n","        x0, y0 = map(int, [0, -r[2] / r[1]])\n","        x1, y1 = map(int, [c, -(r[2] + r[0] * c) / r[1]])\n","        img1 = cv2.line(img1, (x0, y0), (x1, y1), color, 2)\n","        img1 = cv2.circle(img1, (int(pt1[0]), int(pt1[1])), 5, color, -1)\n","        img2 = cv2.circle(img2, (int(pt2[0]), int(pt2[1])), 5, color, -1)\n","    return img1, img2\n","\n","def drawFundamental(img1, img2, pts1, pts2, F):\n","    # Trouver les épilines correspondant à certains points de l'image de droite (deuxième image)\n","    # et dessiner leurs lignes sur l'image de gauche\n","    indexes = np.random.randint(0, pts1.shape[0], size=(10))\n","    indexes = range(pts1.shape[0])\n","    samplePt1 = pts1[indexes, :]\n","    samplePt2 = pts2[indexes, :]\n","\n","    lines1 = cv2.computeCorrespondEpilines(samplePt2.reshape(-1, 1, 2), 2, F)\n","    lines1 = lines1.reshape(-1, 3)\n","    img5, img6 = drawlines(img1, img2, lines1, samplePt1, samplePt2)\n","\n","    # Trouver les épilines correspondant à certains points de l'image de gauche (première image)\n","    # et dessiner leurs lignes sur l'image de droite\n","\n","    lines2 = cv2.computeCorrespondEpilines(samplePt1.reshape(-1, 1, 2), 1, F)\n","    lines2 = lines2.reshape(-1, 3)\n","    img3, img4 = drawlines(img2, img1, lines2, samplePt2, samplePt1)\n","    return img5, img3\n","\n","###### Calcul de la Matrice Fondamentale avec OpenCV RANSAC\n","FRansac, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC,\n","                                       ransacReprojThreshold=0.99,  # Distance max de reprojection en pixels pour un inlier\n","                                       confidence=0.99)  # Niveau de confiance désiré\n","print('Nb inliers RANSAC : ' + str(mask.sum()))\n","\n","# Affichage des inliers uniquement\n","inlierpts1 = pts1[mask.ravel() == 1]\n","inlierpts2 = pts2[mask.ravel() == 1]\n","\n","# Tracer les droites épipolaires\n","imgL, imgR = drawFundamental(img1, img2, inlierpts1, inlierpts2, FRansac)\n","plt.figure(figsize=(15, 5))\n","plt.subplot(121), plt.imshow(imgL)\n","plt.title('Lignes épipolaires des %i inliers (gauche)' % mask.sum())\n","plt.subplot(122), plt.imshow(imgR)\n","plt.title('Lignes épipolaires des %i inliers (droite)' % mask.sum())\n","plt.show()\n"],"metadata":{"id":"ssUVr_3gm3QY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"UDXgRt0Z9jNR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","###### Lecture des deux images\n","input1 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/obj_left.png') # image de droite\n","input2 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/obj_right.png') # image de gauche\n","\n","# Conversion en niveaux de gris\n","img1 = cv2.cvtColor(input1, cv2.COLOR_BGR2GRAY)\n","img2 = cv2.cvtColor(input2, cv2.COLOR_BGR2GRAY)\n","\n","###### Détection des points clefs\n","sift = cv2.SIFT_create()\n","\n","# Détection des points SIFT et calcul des descripteurs\n","kp1, des1 = sift.detectAndCompute(img1, None)\n","kp2, des2 = sift.detectAndCompute(img2, None)\n","\n","print('Nb de points SIFT : ' + str(len(kp1)) + ' (gauche) ' + str(len(kp2)) + ' (droite)')\n","imgd = cv2.drawKeypoints(img1, kp1, None, -1, flags=cv2.DrawMatchesFlags_DEFAULT)\n","plt.imshow(imgd), plt.title('%i Points SIFT (Image de gauche)' % len(kp1))\n","plt.show()\n","\n","pts1 = []\n","pts2 = []\n","\n","# Distance L2 pour descripteur SIFT\n","bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n","# Extraction de la liste des 2-plus-proches-voisins\n","matches = bf.knnMatch(des1, des2, k=2)\n","# Filtrage des appariements par application du ratio test\n","good = []\n","for m, n in matches:\n","    if m.distance < 0.9 * n.distance:\n","        pts2.append(kp2[m.trainIdx].pt)\n","        pts1.append(kp1[m.queryIdx].pt)\n","        good.append([m])\n","\n","mfilt_image = np.array([])\n","draw_params = dict(matchColor=(0, 255, 0),\n","                   singlePointColor=(255, 0, 0),\n","                   flags=0)\n","mfilt_image = cv2.drawMatchesKnn(img1, kp1, img2, kp2, good, None, **draw_params)\n","pts1 = np.float32(pts1)\n","pts2 = np.float32(pts2)\n","print('Nb de paires sélectionnées : ' + str(pts1.shape[0]))\n","\n","plt.figure(figsize=(15, 5))\n","plt.imshow(mfilt_image)\n","plt.title('Appariement filtré : %i paires conservées' % pts1.shape[0])\n","plt.show()\n","\n","##### Définition des fonctions auxiliaires\n","def drawlines(img1, img2, lines, pts1, pts2):\n","    ''' img1 - image sur laquelle on dessine les épilines pour les points dans img2\n","        lines - épilines correspondantes '''\n","    r, c = img1.shape\n","    img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n","    img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n","    for r, pt1, pt2 in zip(lines, pts1, pts2):\n","        color = tuple(cv2.cvtColor(np.asarray([[[np.random.randint(0, 180), 255, 255]]], dtype=np.uint8), cv2.COLOR_HSV2BGR)[0, 0, :].tolist())\n","        x0, y0 = map(int, [0, -r[2] / r[1]])\n","        x1, y1 = map(int, [c, -(r[2] + r[0] * c) / r[1]])\n","        img1 = cv2.line(img1, (x0, y0), (x1, y1), color, 2)\n","        img1 = cv2.circle(img1, (int(pt1[0]), int(pt1[1])), 5, color, -1)\n","        img2 = cv2.circle(img2, (int(pt2[0]), int(pt2[1])), 5, color, -1)\n","    return img1, img2\n","\n","def drawFundamental(img1, img2, pts1, pts2, F):\n","    # Trouver les épilines correspondant à certains points de l'image de droite (deuxième image)\n","    # et dessiner leurs lignes sur l'image de gauche\n","    indexes = np.random.randint(0, pts1.shape[0], size=(10))\n","    indexes = range(pts1.shape[0])\n","    samplePt1 = pts1[indexes, :]\n","    samplePt2 = pts2[indexes, :]\n","\n","    lines1 = cv2.computeCorrespondEpilines(samplePt2.reshape(-1, 1, 2), 2, F)\n","    lines1 = lines1.reshape(-1, 3)\n","    img5, img6 = drawlines(img1, img2, lines1, samplePt1, samplePt2)\n","\n","    # Trouver les épilines correspondant à certains points de l'image de gauche (première image)\n","    # et dessiner leurs lignes sur l'image de droite\n","    lines2 = cv2.computeCorrespondEpilines(samplePt1.reshape(-1, 1, 2), 1, F)\n","    lines2 = lines2.reshape(-1, 3)\n","    img3, img4 = drawlines(img2, img1, lines2, samplePt2, samplePt1)\n","    return img5, img3\n","\n","###### Calcul de la Matrice Fondamentale avec OpenCV RANSAC\n","FRansac, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC,\n","                                       ransacReprojThreshold=0.5,  # Distance max de reprojection en pixels pour un inlier\n","                                       confidence=0.99)  # Niveau de confiance désiré\n","print('Nb inliers RANSAC : ' + str(mask.sum()))\n","\n","# Affichage des inliers uniquement\n","inlierpts1 = pts1[mask.ravel() == 1]\n","inlierpts2 = pts2[mask.ravel() == 1]\n","\n","# Tracer les droites épipolaires\n","imgL, imgR = drawFundamental(img1, img2, inlierpts1, inlierpts2, FRansac)\n","plt.figure(figsize=(15, 5))\n","plt.subplot(121), plt.imshow(imgL)\n","plt.title('Lignes épipolaires des %i inliers (gauche)' % mask.sum())\n","plt.subplot(122), plt.imshow(imgR)\n","plt.title('Lignes épipolaires des %i inliers (droite)' % mask.sum())\n","plt.show()\n","\n","###### Calcul de la carte de disparité\n","# Assurez-vous que les deux images ont la même taille\n","height, width = img1.shape\n","if img2.shape != img1.shape:\n","    img2 = cv2.resize(img2, (width, height))\n","\n","# Calcul de la carte de disparité avec StereoSGBM\n","min_disp = 0\n","num_disp = 16*5  # Doit être multiple de 16\n","block_size = 5\n","\n","stereo = cv2.StereoSGBM_create(minDisparity=min_disp,\n","    numDisparities=num_disp,\n","    blockSize=block_size,\n","    P1=8 * 3 * block_size ** 2,\n","    P2=32 * 3 * block_size ** 2,\n","    disp12MaxDiff=1,\n","    uniquenessRatio=10,\n","    speckleWindowSize=100,\n","    speckleRange=32,\n","    preFilterCap=63,\n","    mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY)\n","\n","disparity = stereo.compute(img1, img2).astype(np.float32) / 16.0\n","\n","# Affichage de la carte de disparité\n","plt.figure(figsize=(10, 5))\n","plt.title(\"Carte de Disparité\")\n","plt.imshow(disparity, 'gray')\n","plt.colorbar()\n","plt.show()\n"],"metadata":{"id":"GKsaPih2A1kM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","###### Lecture des deux images\n","input1 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/obj_left.png') # image de droite\n","input2 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/obj_right.png') # image de gauche\n","\n","# Conversion en niveaux de gris\n","img1 = cv2.cvtColor(input1, cv2.COLOR_BGR2GRAY)\n","img2 = cv2.cvtColor(input2, cv2.COLOR_BGR2GRAY)\n","\n","# Pré-traitement des images\n","img1 = cv2.GaussianBlur(img1, (5, 5), 0)\n","img2 = cv2.GaussianBlur(img2, (5, 5), 0)\n","\n","###### Détection des points clefs\n","sift = cv2.SIFT_create()\n","\n","# Détection des points SIFT et calcul des descripteurs\n","kp1, des1 = sift.detectAndCompute(img1, None)\n","kp2, des2 = sift.detectAndCompute(img2, None)\n","\n","print('Nb de points SIFT : ' + str(len(kp1)) + ' (gauche) ' + str(len(kp2)) + ' (droite)')\n","imgd = cv2.drawKeypoints(img1, kp1, None, -1, flags=cv2.DrawMatchesFlags_DEFAULT)\n","plt.imshow(imgd), plt.title('%i Points SIFT (Image de gauche)' % len(kp1))\n","plt.show()\n","\n","pts1 = []\n","pts2 = []\n","\n","# Distance L2 pour descripteur SIFT\n","bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n","# Extraction de la liste des 2-plus-proches-voisins\n","matches = bf.knnMatch(des1, des2, k=2)\n","# Filtrage des appariements par application du ratio test\n","good = []\n","for m, n in matches:\n","    if m.distance < 0.7 * n.distance:\n","        pts2.append(kp2[m.trainIdx].pt)\n","        pts1.append(kp1[m.queryIdx].pt)\n","        good.append([m])\n","\n","mfilt_image = np.array([])\n","draw_params = dict(matchColor=(0, 255, 0),\n","                   singlePointColor=(255, 0, 0),\n","                   flags=0)\n","mfilt_image = cv2.drawMatchesKnn(img1, kp1, img2, kp2, good, None, **draw_params)\n","pts1 = np.float32(pts1)\n","pts2 = np.float32(pts2)\n","print('Nb de paires sélectionnées : ' + str(pts1.shape[0]))\n","\n","plt.figure(figsize=(15, 5))\n","plt.imshow(mfilt_image)\n","plt.title('Appariement filtré : %i paires conservées' % pts1.shape[0])\n","plt.show()\n","\n","##### Définition des fonctions auxiliaires\n","def drawlines(img1, img2, lines, pts1, pts2):\n","    ''' img1 - image sur laquelle on dessine les épilines pour les points dans img2\n","        lines - épilines correspondantes '''\n","    r, c = img1.shape\n","    img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n","    img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n","    for r, pt1, pt2 in zip(lines, pts1, pts2):\n","        color = tuple(cv2.cvtColor(np.asarray([[[np.random.randint(0, 180), 255, 255]]], dtype=np.uint8), cv2.COLOR_HSV2BGR)[0, 0, :].tolist())\n","        x0, y0 = map(int, [0, -r[2] / r[1]])\n","        x1, y1 = map(int, [c, -(r[2] + r[0] * c) / r[1]])\n","        img1 = cv2.line(img1, (x0, y0), (x1, y1), color, 2)\n","        img1 = cv2.circle(img1, (int(pt1[0]), int(pt1[1])), 5, color, -1)\n","        img2 = cv2.circle(img2, (int(pt2[0]), int(pt2[1])), 5, color, -1)\n","    return img1, img2\n","\n","def drawFundamental(img1, img2, pts1, pts2, F):\n","    # Trouver les épilines correspondant à certains points de l'image de droite (deuxième image)\n","    # et dessiner leurs lignes sur l'image de gauche\n","    indexes = np.random.randint(0, pts1.shape[0], size=(10))\n","    indexes = range(pts1.shape[0])\n","    samplePt1 = pts1[indexes, :]\n","    samplePt2 = pts2[indexes, :]\n","\n","    lines1 = cv2.computeCorrespondEpilines(samplePt2.reshape(-1, 1, 2), 2, F)\n","    lines1 = lines1.reshape(-1, 3)\n","    img5, img6 = drawlines(img1, img2, lines1, samplePt1, samplePt2)\n","\n","    # Trouver les épilines correspondant à certains points de l'image de gauche (première image)\n","    # et dessiner leurs lignes sur l'image de droite\n","    lines2 = cv2.computeCorrespondEpilines(samplePt1.reshape(-1, 1, 2), 1, F)\n","    lines2 = lines2.reshape(-1, 3)\n","    img3, img4 = drawlines(img2, img1, lines2, samplePt2, samplePt1)\n","    return img5, img3\n","\n","###### Calcul de la Matrice Fondamentale avec OpenCV RANSAC\n","FRansac, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC,\n","                                       ransacReprojThreshold=0.5,  # Distance max de reprojection en pixels pour un inlier\n","                                       confidence=0.99)  # Niveau de confiance désiré\n","print('Nb inliers RANSAC : ' + str(mask.sum()))\n","\n","# Affichage des inliers uniquement\n","inlierpts1 = pts1[mask.ravel() == 1]\n","inlierpts2 = pts2[mask.ravel() == 1]\n","\n","# Tracer les droites épipolaires\n","imgL, imgR = drawFundamental(img1, img2, inlierpts1, inlierpts2, FRansac)\n","plt.figure(figsize=(15, 5))\n","plt.subplot(121), plt.imshow(imgL)\n","plt.title('Lignes épipolaires des %i inliers (gauche)' % mask.sum())\n","plt.subplot(122), plt.imshow(imgR)\n","plt.title('Lignes épipolaires des %i inliers (droite)' % mask.sum())\n","plt.show()\n","\n","###### Calcul de la carte de disparité\n","# Assurez-vous que les deux images ont la même taille\n","height, width = img1.shape\n","if img2.shape != img1.shape:\n","    img2 = cv2.resize(img2, (width, height))\n","\n","# Calcul de la carte de disparité avec StereoSGBM\n","min_disp = 0\n","num_disp = 16*11  # Doit être multiple de 16\n","block_size = 11\n","\n","stereo = cv2.StereoSGBM_create(minDisparity=min_disp,\n","    numDisparities=num_disp,\n","    blockSize=block_size,\n","    P1=32 * 3 * block_size ** 2,\n","    P2=64 * 3 * block_size ** 2,\n","    disp12MaxDiff=1,\n","    uniquenessRatio=5,\n","    speckleWindowSize=50,\n","    speckleRange=32,\n","    preFilterCap=63,\n","    mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY)\n","\n","disparity = stereo.compute(img1, img2).astype(np.float32) / 16.0\n","\n","# Normaliser la disparité pour l'afficher correctement\n","disparity = (disparity - min_disp) / num_disp\n","\n","# Affichage de la carte de disparité\n","plt.figure(figsize=(10, 5))\n","plt.title(\"Carte de Disparité\")\n","plt.imshow(disparity, 'gray')\n","plt.colorbar()\n","plt.show()"],"metadata":{"id":"FwF_VQ_iC0sC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","# Lecture des deux images\n","input1 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imLeft.png')  # image de gauche\n","input2 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imRight.png')  # image de droite\n","\n","# Conversion en niveaux de gris\n","img1 = cv2.cvtColor(input1, cv2.COLOR_BGR2GRAY)\n","img2 = cv2.cvtColor(input2, cv2.COLOR_BGR2GRAY)\n","\n","# Pré-traitement des images\n","img1 = cv2.GaussianBlur(img1, (5, 5), 0)\n","img2 = cv2.GaussianBlur(img2, (5, 5), 0)\n","\n","# Détection des points clefs\n","sift = cv2.SIFT_create()\n","\n","# Détection des points SIFT et calcul des descripteurs\n","kp1, des1 = sift.detectAndCompute(img1, None)\n","kp2, des2 = sift.detectAndCompute(img2, None)\n","\n","print('Nb de points SIFT : ' + str(len(kp1)) + ' (gauche) ' + str(len(kp2)) + ' (droite)')\n","imgd = cv2.drawKeypoints(img1, kp1, None, -1, flags=cv2.DrawMatchesFlags_DEFAULT)\n","plt.imshow(imgd), plt.title('%i Points SIFT (Image de gauche)' % len(kp1))\n","plt.show()\n","\n","pts1 = []\n","pts2 = []\n","\n","# Distance L2 pour descripteur SIFT\n","bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n","# Extraction de la liste des 2-plus-proches-voisins\n","matches = bf.knnMatch(des1, des2, k=2)\n","# Filtrage des appariements par application du ratio test\n","good = []\n","for m, n in matches:\n","    if m.distance < 0.2 * n.distance:\n","        pts2.append(kp2[m.trainIdx].pt)\n","        pts1.append(kp1[m.queryIdx].pt)\n","        good.append([m])\n","\n","# Limiter à 50 paires de points\n","pts1 = np.array(pts1[:50])\n","pts2 = np.array(pts2[:50])\n","good = good[:50]\n","\n","# Dessiner les correspondances\n","draw_params = dict(matchColor=(0, 255, 0),\n","                   singlePointColor=(255, 0, 0),\n","                   flags=0)\n","mfilt_image = cv2.drawMatchesKnn(img1, kp1, img2, kp2, good, None, **draw_params)\n","print('Nb de paires sélectionnées : ' + str(pts1.shape[0]))\n","\n","plt.figure(figsize=(15, 5))\n","plt.imshow(mfilt_image)\n","plt.title('Appariement filtré : %i paires conservées' % pts1.shape[0])\n","plt.show()\n","\n","# Définition des fonctions auxiliaires\n","def drawlines(img1, img2, lines, pts1, pts2):\n","    ''' img1 - image sur laquelle on dessine les épilines pour les points dans img2\n","        lines - épilines correspondantes '''\n","    r, c = img1.shape\n","    img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n","    img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n","    for r, pt1, pt2 in zip(lines, pts1, pts2):\n","        color = tuple(cv2.cvtColor(np.asarray([[[np.random.randint(0, 180), 255, 255]]], dtype=np.uint8), cv2.COLOR_HSV2BGR)[0, 0, :].tolist())\n","        x0, y0 = map(int, [0, -r[2] / r[1]])\n","        x1, y1 = map(int, [c, -(r[2] + r[0] * c) / r[1]])\n","        img1 = cv2.line(img1, (x0, y0), (x1, y1), color, 2)\n","        img1 = cv2.circle(img1, (int(pt1[0]), int(pt1[1])), 5, color, -1)\n","        img2 = cv2.circle(img2, (int(pt2[0]), int(pt2[1])), 5, color, -1)\n","    return img1, img2\n","\n","def drawFundamental(img1, img2, pts1, pts2, F):\n","    # Trouver les épilines correspondant à certains points de l'image de droite (deuxième image)\n","    # et dessiner leurs lignes sur l'image de gauche\n","    indexes = np.random.randint(0, pts1.shape[0], size=(10))\n","    samplePt1 = pts1[indexes, :]\n","    samplePt2 = pts2[indexes, :]\n","\n","    lines1 = cv2.computeCorrespondEpilines(samplePt2.reshape(-1, 1, 2), 2, F)\n","    lines1 = lines1.reshape(-1, 3)\n","    img5, img6 = drawlines(img1, img2, lines1, samplePt1, samplePt2)\n","\n","    # Trouver les épilines correspondant à certains points de l'image de gauche (première image)\n","    # et dessiner leurs lignes sur l'image de droite\n","    lines2 = cv2.computeCorrespondEpilines(samplePt1.reshape(-1, 1, 2), 1, F)\n","    lines2 = lines2.reshape(-1, 3)\n","    img3, img4 = drawlines(img2, img1, lines2, samplePt2, samplePt1)\n","    return img5, img3\n","\n","# Calcul de la Matrice Fondamentale avec OpenCV RANSAC\n","FRansac, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC,\n","                                       ransacReprojThreshold=1.0,  # Distance max de reprojection en pixels pour un inlier\n","                                       confidence=0.99)  # Niveau de confiance désiré\n","print('Nb inliers RANSAC : ' + str(mask.sum()))\n","\n","# Affichage des inliers uniquement\n","inlierpts1 = pts1[mask.ravel() == 1]\n","inlierpts2 = pts2[mask.ravel() == 1]\n","\n","# Tracer les droites épipolaires\n","imgL, imgR = drawFundamental(img1, img2, inlierpts1, inlierpts2, FRansac)\n","plt.figure(figsize=(15, 5))\n","plt.subplot(121), plt.imshow(imgL)\n","plt.title('Lignes épipolaires des %i inliers (gauche)' % mask.sum())\n","plt.subplot(122), plt.imshow(imgR)\n","plt.title('Lignes épipolaires des %i inliers (droite)' % mask.sum())\n","plt.show()\n","\n","# Calcul de la carte de disparité\n","# Assurez-vous que les deux images ont la même taille\n","height, width = img1.shape\n","if img2.shape != img1.shape:\n","    img2 = cv2.resize(img2, (width, height))\n","\n","# Calcul de la carte de disparité avec StereoSGBM\n","min_disp = 0\n","num_disp = 16*3  # Doit être multiple de 16\n","block_size = 5\n","\n","stereo = cv2.StereoSGBM_create(minDisparity=min_disp,\n","    numDisparities=num_disp,\n","    blockSize=block_size,\n","    P1=8 * 3 * block_size ** 2,\n","    P2=32 * 3 * block_size ** 2,\n","    disp12MaxDiff=1,\n","    uniquenessRatio=10,\n","    speckleWindowSize=100,\n","    speckleRange=32,\n","    preFilterCap=63,\n","    mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY)\n","\n","disparity = stereo.compute(img1, img2).astype(np.float32) / 16.0\n","\n","# Normaliser la disparité pour l'afficher correctement\n","disparity = (disparity - min_disp) / num_disp\n","\n","# Appliquer une colormap pour mieux visualiser la disparité\n","disparity_colormap = cv2.applyColorMap((disparity * 255).astype(np.uint8), cv2.COLORMAP_JET)\n","\n","# Affichage de la carte de disparité\n","plt.figure(figsize=(10, 5))\n","plt.title(\"Carte de Disparité\")\n","plt.imshow(disparity_colormap)\n","plt.colorbar()\n","plt.show()\n"],"metadata":{"id":"_z6OpjLFOFvp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","# Lecture des deux images\n","input1 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imLeft.png') # image de gauche\n","input2 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imRight.png') # image de droite\n","# Conversion en niveaux de gris\n","img1 = cv2.cvtColor(input1, cv2.COLOR_BGR2GRAY)\n","img2 = cv2.cvtColor(input2, cv2.COLOR_BGR2GRAY)\n","\n","# Pré-traitement des images\n","img1 = cv2.GaussianBlur(img1, (5, 5), 0)\n","img2 = cv2.GaussianBlur(img2, (5, 5), 0)\n","\n","###### Détection des points clefs\n","sift = cv2.SIFT_create()\n","\n","# Détection des points SIFT et calcul des descripteurs\n","kp1, des1 = sift.detectAndCompute(img1, None)\n","kp2, des2 = sift.detectAndCompute(img2, None)\n","\n","print('Nb de points SIFT : ' + str(len(kp1)) + ' (gauche) ' + str(len(kp2)) + ' (droite)')\n","imgd = cv2.drawKeypoints(img1, kp1, None, -1, flags=cv2.DrawMatchesFlags_DEFAULT)\n","plt.imshow(imgd), plt.title('%i Points SIFT (Image de gauche)' % len(kp1))\n","plt.show()\n","\n","pts1 = []\n","pts2 = []\n","\n","# Distance L2 pour descripteur SIFT\n","bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n","# Extraction de la liste des 2-plus-proches-voisins\n","matches = bf.knnMatch(des1, des2, k=2)\n","# Filtrage des appariements par application du ratio test\n","good = []\n","for m, n in matches:\n","    if m.distance < 0.2 * n.distance:\n","        pts2.append(kp2[m.trainIdx].pt)\n","        pts1.append(kp1[m.queryIdx].pt)\n","        good.append([m])\n","\n","mfilt_image = np.array([])\n","draw_params = dict(matchColor=(0, 255, 0),\n","                   singlePointColor=(255, 0, 0),\n","                   flags=0)\n","mfilt_image = cv2.drawMatchesKnn(img1, kp1, img2, kp2, good, None, **draw_params)\n","pts1 = np.float32(pts1)\n","pts2 = np.float32(pts2)\n","print('Nb de paires sélectionnées : ' + str(pts1.shape[0]))\n","\n","plt.figure(figsize=(15, 5))\n","plt.imshow(mfilt_image)\n","plt.title('Appariement filtré : %i paires conservées' % pts1.shape[0])\n","plt.show()\n","\n","##### Définition des fonctions auxiliaires\n","def drawlines(img1, img2, lines, pts1, pts2):\n","    ''' img1 - image sur laquelle on dessine les épilines pour les points dans img2\n","        lines - épilines correspondantes '''\n","    r, c = img1.shape\n","    img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n","    img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n","    for r, pt1, pt2 in zip(lines, pts1, pts2):\n","        color = tuple(cv2.cvtColor(np.asarray([[[np.random.randint(0, 180), 255, 255]]], dtype=np.uint8), cv2.COLOR_HSV2BGR)[0, 0, :].tolist())\n","        x0, y0 = map(int, [0, -r[2] / r[1]])\n","        x1, y1 = map(int, [c, -(r[2] + r[0] * c) / r[1]])\n","        img1 = cv2.line(img1, (x0, y0), (x1, y1), color, 2)\n","        img1 = cv2.circle(img1, (int(pt1[0]), int(pt1[1])), 5, color, -1)\n","        img2 = cv2.circle(img2, (int(pt2[0]), int(pt2[1])), 5, color, -1)\n","    return img1, img2\n","\n","def drawFundamental(img1, img2, pts1, pts2, F):\n","    # Limiter le nombre de points à 100 pour un affichage clair\n","    if len(pts1) > 100:\n","        indices = np.random.choice(len(pts1), 100, replace=False)\n","        pts1 = pts1[indices]\n","        pts2 = pts2[indices]\n","\n","    # Trouver les épilines correspondant à certains points de l'image de droite (deuxième image)\n","    lines1 = cv2.computeCorrespondEpilines(pts2.reshape(-1, 1, 2), 2, F)\n","    lines1 = lines1.reshape(-1, 3)\n","    img5, img6 = drawlines(img1, img2, lines1, pts1, pts2)\n","\n","    # Trouver les épilines correspondant à certains points de l'image de gauche (première image)\n","    lines2 = cv2.computeCorrespondEpilines(pts1.reshape(-1, 1, 2), 1, F)\n","    lines2 = lines2.reshape(-1, 3)\n","    img3, img4 = drawlines(img2, img1, lines2, pts2, pts1)\n","    return img5, img3\n","\n","###### Calcul de la Matrice Fondamentale avec OpenCV RANSAC\n","FRansac, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC,\n","                                       ransacReprojThreshold=0.5,  # Distance max de reprojection en pixels pour un inlier\n","                                       confidence=0.99)  # Niveau de confiance désiré\n","\n","if mask is not None:\n","    print('Nb inliers RANSAC : ' + str(mask.sum()))\n","\n","    # Affichage des inliers uniquement\n","    inlierpts1 = pts1[mask.ravel() == 1]\n","    inlierpts2 = pts2[mask.ravel() == 1]\n","\n","    # Tracer les droites épipolaires\n","    imgL, imgR = drawFundamental(img1, img2, inlierpts1, inlierpts2, FRansac)\n","    combined_img = np.hstack((imgL, imgR))\n","    plt.figure(figsize=(15, 5))\n","    plt.imshow(combined_img)\n","    plt.title('Lignes épipolaires des %i inliers' % mask.sum())\n","    plt.show()\n","\n","    # Rectification des images\n","    h1, w1 = img1.shape\n","    h2, w2 = img2.shape\n","    _, H1, H2 = cv2.stereoRectifyUncalibrated(np.float32(inlierpts1), np.float32(inlierpts2), FRansac, (w1, h1))\n","\n","    img1_rectified = cv2.warpPerspective(img1, H1, (w1, h1))\n","    img2_rectified = cv2.warpPerspective(img2, H2, (w2, h2))\n","\n","    # Tracer les droites épipolaires sur les images rectifiées\n","    imgL_rect, imgR_rect = drawFundamental(img1_rectified, img2_rectified, inlierpts1, inlierpts2, FRansac)\n","    combined_img_rect = np.hstack((imgL_rect, imgR_rect))\n","    plt.figure(figsize=(15, 5))\n","    plt.imshow(combined_img_rect)\n","    plt.title('Images rectifiées avec épilines corrigées (gauche et droite)')\n","    plt.show()\n","\n","    # Calcul de la carte de disparité\n","    # Assurez-vous que les deux images rectifiées ont la même taille\n","    height, width = img1_rectified.shape\n","    if img2_rectified.shape != img1_rectified.shape:\n","        img2_rectified = cv2.resize(img2_rectified, (width, height))\n","\n","    # Calcul de la carte de disparité avec StereoSGBM\n","    min_disp = 0\n","    num_disp = 16*5  # Doit être multiple de 16\n","    block_size = 5\n","\n","    stereo = cv2.StereoSGBM_create(minDisparity=min_disp,\n","        numDisparities=num_disp,\n","        blockSize=block_size,\n","        P1=8 * 3 * block_size ** 2,\n","        P2=32 * 3 * block_size ** 2,\n","        disp12MaxDiff=1,\n","        uniquenessRatio=10,\n","        speckleWindowSize=100,\n","        speckleRange=32,\n","        preFilterCap=63,\n","        mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY)\n","\n","    disparity = stereo.compute(img1_rectified, img2_rectified).astype(np.float32) / 16.0\n","\n","    # Normaliser la disparité pour l'afficher correctement\n","    # Normaliser la disparité pour l'afficher correctement\n","disparity = (disparity - min_disp) / num_disp\n","\n","# Appliquer une colormap pour mieux visualiser la disparité\n","disparity_colormap = cv2.applyColorMap((disparity * 255).astype(np.uint8), cv2.COLORMAP_JET)\n","\n","# Affichage de la carte de disparité\n","plt.figure(figsize=(10, 5))\n","plt.title(\"Carte de Disparité\")\n","plt.imshow(disparity_colormap)\n","plt.colorbar()\n","plt.show()\n","\n","# Fonction pour dessiner les lignes épipolaires avec correspondance de couleur correcte\n","def draw_corrected_epilines(img1, img2, pts1, pts2, F):\n","    # Limiter le nombre de points à 100 pour un affichage clair\n","    if len(pts1) > 100:\n","        indices = np.random.choice(len(pts1), 100, replace=False)\n","        pts1 = pts1[indices]\n","        pts2 = pts2[indices]\n","\n","    # Trouver les épilines correspondant à certains points de l'image de droite (deuxième image)\n","    lines1 = cv2.computeCorrespondEpilines(pts2.reshape(-1, 1, 2), 2, F)\n","    lines1 = lines1.reshape(-1, 3)\n","    img1_lines, img2_points = drawlines(img1, img2, lines1, pts1, pts2)\n","\n","    # Trouver les épilines correspondant à certains points de l'image de gauche (première image)\n","    lines2 = cv2.computeCorrespondEpilines(pts1.reshape(-1, 1, 2), 1, F)\n","    lines2 = lines2.reshape(-1, 3)\n","    img2_lines, img1_points = drawlines(img2, img1, lines2, pts2, pts1)\n","\n","    return img1_lines, img2_lines\n","\n","# Tracer les droites épipolaires avec correspondance de couleur correcte\n","imgL_corr, imgR_corr = draw_corrected_epilines(img1, img2, inlierpts1, inlierpts2, FRansac)\n","\n","# Affichage des images avec épilines corrigées\n","combined_img_corr = np.hstack((imgL_corr, imgR_corr))\n","plt.figure(figsize=(15, 5))\n","plt.imshow(combined_img_corr)\n","plt.title('Lignes épipolaires corrigées (gauche et droite)')\n","plt.show()\n","\n","# Rectification des images avec épilines corrigées\n","img1_rectified_corr = cv2.warpPerspective(img1, H1, (w1, h1))\n","img2_rectified_corr = cv2.warpPerspective(img2, H2, (w2, h2))\n","\n","# Tracer les droites épipolaires sur les images rectifiées avec correspondance de couleur correcte\n","imgL_rect_corr, imgR_rect_corr = draw_corrected_epilines(img1_rectified_corr, img2_rectified_corr, inlierpts1, inlierpts2, FRansac)\n","\n","# Affichage des images rectifiées avec épilines corrigées\n","combined_img_rect_corr = np.hstack((imgL_rect_corr, imgR_rect_corr))\n","plt.figure(figsize=(15, 5))\n","plt.imshow(combined_img_rect_corr)\n","plt.title('Images rectifiées avec épilines corrigées (gauche et droite)')\n","plt.show()\n"],"metadata":{"id":"lI8HSP5MRsZw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","# Lecture des deux images\n","input1 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imLeft.png') # image de gauche\n","input2 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imRight.png') # image de droite\n","# Conversion en niveaux de gris\n","img1 = cv2.cvtColor(input1, cv2.COLOR_BGR2GRAY)\n","img2 = cv2.cvtColor(input2, cv2.COLOR_BGR2GRAY)\n","\n","# Pré-traitement des images\n","img1 = cv2.GaussianBlur(img1, (5, 5), 0)\n","img2 = cv2.GaussianBlur(img2, (5, 5), 0)\n","\n","###### Détection des points clefs\n","sift = cv2.SIFT_create()\n","\n","# Détection des points SIFT et calcul des descripteurs\n","kp1, des1 = sift.detectAndCompute(img1, None)\n","kp2, des2 = sift.detectAndCompute(img2, None)\n","\n","print('Nb de points SIFT : ' + str(len(kp1)) + ' (gauche) ' + str(len(kp2)) + ' (droite)')\n","imgd = cv2.drawKeypoints(img1, kp1, None, -1, flags=cv2.DrawMatchesFlags_DEFAULT)\n","plt.imshow(imgd), plt.title('%i Points SIFT (Image de gauche)' % len(kp1))\n","plt.show()\n","\n","pts1 = []\n","pts2 = []\n","\n","# Distance L2 pour descripteur SIFT\n","bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=False)\n","# Extraction de la liste des 2-plus-proches-voisins\n","matches = bf.knnMatch(des1, des2, k=2)\n","# Filtrage des appariements par application du ratio test\n","good = []\n","for m, n in matches:\n","    if m.distance < 0.1 * n.distance:\n","        pts2.append(kp2[m.trainIdx].pt)\n","        pts1.append(kp1[m.queryIdx].pt)\n","        good.append([m])\n","\n","mfilt_image = np.array([])\n","draw_params = dict(matchColor=(0, 255, 0),\n","                   singlePointColor=(255, 0, 0),\n","                   flags=0)\n","mfilt_image = cv2.drawMatchesKnn(img1, kp1, img2, kp2, good, None, **draw_params)\n","pts1 = np.float32(pts1)\n","pts2 = np.float32(pts2)\n","print('Nb de paires sélectionnées : ' + str(pts1.shape[0]))\n","\n","plt.figure(figsize=(15, 5))\n","plt.imshow(mfilt_image)\n","plt.title('Appariement filtré : %i paires conservées' % pts1.shape[0])\n","plt.show()\n","\n","##### Définition des fonctions auxiliaires\n","def drawlines(img1, img2, lines, pts1, pts2):\n","    ''' img1 - image sur laquelle on dessine les épilines pour les points dans img2\n","        lines - épilines correspondantes '''\n","    r, c = img1.shape\n","    img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n","    img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n","    for r, pt1, pt2 in zip(lines, pts1, pts2):\n","        color = tuple(cv2.cvtColor(np.asarray([[[np.random.randint(0, 180), 255, 255]]], dtype=np.uint8), cv2.COLOR_HSV2BGR)[0, 0, :].tolist())\n","        x0, y0 = map(int, [0, -r[2] / r[1]])\n","        x1, y1 = map(int, [c, -(r[2] + r[0] * c) / r[1]])\n","        img1 = cv2.line(img1, (x0, y0), (x1, y1), color, 2)\n","        img1 = cv2.circle(img1, (int(pt1[0]), int(pt1[1])), 5, color, -1)\n","        img2 = cv2.circle(img2, (int(pt2[0]), int(pt2[1])), 5, color, -1)\n","    return img1, img2\n","\n","def drawFundamental(img1, img2, pts1, pts2, F):\n","    # Trouver les épilines correspondant à certains points de l'image de droite (deuxième image)\n","    # et dessiner leurs lignes sur l'image de gauche\n","    indexes = np.random.randint(0, pts1.shape[0], size=(10))\n","    indexes = range(pts1.shape[0])\n","    samplePt1 = pts1[indexes, :]\n","    samplePt2 = pts2[indexes, :]\n","\n","    lines1 = cv2.computeCorrespondEpilines(samplePt2.reshape(-1, 1, 2), 2, F)\n","    lines1 = lines1.reshape(-1, 3)\n","    img5, img6 = drawlines(img1, img2, lines1, samplePt1, samplePt2)\n","\n","    # Trouver les épilines correspondant à certains points de l'image de gauche (première image)\n","    # et dessiner leurs lignes sur l'image de droite\n","    lines2 = cv2.computeCorrespondEpilines(samplePt1.reshape(-1, 1, 2), 1, F)\n","    lines2 = lines2.reshape(-1, 3)\n","    img3, img4 = drawlines(img2, img1, lines2, samplePt2, samplePt1)\n","    return img5, img3\n","\n","###### Calcul de la Matrice Fondamentale avec OpenCV RANSAC\n","FRansac, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC,\n","                                       ransacReprojThreshold=0.5,  # Distance max de reprojection en pixels pour un inlier\n","                                       confidence=0.99)  # Niveau de confiance désiré\n","print('Nb inliers RANSAC : ' + str(mask.sum()))\n","\n","# Affichage des inliers uniquement\n","inlierpts1 = pts1[mask.ravel() == 1]\n","inlierpts2 = pts2[mask.ravel() == 1]\n","\n","# Tracer les droites épipolaires\n","imgL, imgR = drawFundamental(img1, img2, inlierpts1, inlierpts2, FRansac)\n","plt.figure(figsize=(15, 5))\n","plt.subplot(121), plt.imshow(imgL)\n","plt.title('Lignes épipolaires des %i inliers (gauche)' % mask.sum())\n","plt.subplot(122), plt.imshow(imgR)\n","plt.title('Lignes épipolaires des %i inliers (droite)' % mask.sum())\n","plt.show()\n","\n","# Rectification des images\n","h1, w1 = img1.shape\n","h2, w2 = img2.shape\n","_, H1, H2 = cv2.stereoRectifyUncalibrated(np.float32(inlierpts1), np.float32(inlierpts2), FRansac, (w1, h1))\n","\n","img1_rectified = cv2.warpPerspective(img1, H1, (w1, h1))\n","img2_rectified = cv2.warpPerspective(img2, H2, (w2, h2))\n","\n","# Tracer les droites épipolaires sur les images rectifiées\n","imgL_rect, imgR_rect = drawFundamental(img1_rectified, img2_rectified, inlierpts1, inlierpts2, FRansac)\n","\n","# Affichage des images rectifiées\n","plt.figure(figsize=(15, 5))\n","plt.subplot(121), plt.imshow(imgL_rect, cmap='gray')\n","plt.title('Image gauche rectifiée avec épilines')\n","plt.subplot(122), plt.imshow(imgR_rect, cmap='gray')\n","plt.title('Image droite rectifiée avec épilines')\n","plt.show()\n","\n","###### Calcul de la carte de disparité\n","# Assurez-vous que les deux images rectifiées ont la même taille\n","height, width = img1_rectified.shape\n","if img2_rectified.shape != img1_rectified.shape:\n","    img2_rectified = cv2.resize(img2_rectified, (width, height))\n","\n","# Calcul de la carte de disparité avec StereoSGBM\n","min_disp = 0\n","num_disp = 16*5  # Doit être multiple de 16\n","block_size = 5\n","\n","stereo = cv2.StereoSGBM_create(minDisparity=min_disp,\n","    numDisparities=num_disp,\n","    blockSize=block_size,\n","    P1=8 * 3 * block_size ** 2,\n","    P2=32 * 3 * block_size ** 2,\n","    disp12MaxDiff=1,\n","    uniquenessRatio=10,\n","    speckleWindowSize=100,\n","    speckleRange=32,\n","    preFilterCap=63,\n","    mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY)\n","\n","# Appliquer une colormap pour mieux visualiser la disparité\n","disparity_colormap = cv2.applyColorMap((disparity * 255).astype(np.uint8), cv2.COLORMAP_JET)\n","\n","# Affichage de la carte de disparité\n","plt.figure(figsize=(10, 5))\n","plt.title(\"Carte de Disparité\")\n","plt.imshow(disparity_colormap)\n","plt.colorbar()\n","plt.show()\n","\n","# Fonction pour dessiner les lignes épipolaires avec correspondance de couleur correcte\n","def draw_corrected_epilines(img1, img2, pts1, pts2, F):\n","    # Trouver les épilines correspondant à certains points de l'image de droite (deuxième image)\n","    lines1 = cv2.computeCorrespondEpilines(pts2.reshape(-1, 1, 2), 2, F)\n","    lines1 = lines1.reshape(-1, 3)\n","    img1_lines, img2_points = drawlines(img1, img2, lines1, pts1, pts2)\n","\n","    # Trouver les épilines correspondant à certains points de l'image de gauche (première image)\n","    lines2 = cv2.computeCorrespondEpilines(pts1.reshape(-1, 1, 2), 1, F)\n","    lines2 = lines2.reshape(-1, 3)\n","    img2_lines, img1_points = drawlines(img2, img1, lines2, pts2, pts1)\n","\n","    return img1_lines, img2_lines\n","\n","# Tracer les droites épipolaires avec correspondance de couleur correcte\n","imgL_corr, imgR_corr = draw_corrected_epilines(img1, img2, inlierpts1, inlierpts2, FRansac)\n","\n","# Affichage des images avec épilines corrigées\n","plt.figure(figsize=(15, 5))\n","plt.subplot(121), plt.imshow(imgL_corr)\n","plt.title('Lignes épipolaires corrigées (gauche)')\n","plt.subplot(122), plt.imshow(imgR_corr)\n","plt.title('Lignes épipolaires corrigées (droite)')\n","plt.show()\n","\n","# Rectification des images\n","img1_rectified_corr = cv2.warpPerspective(img1, H1, (w1, h1))\n","img2_rectified_corr = cv2.warpPerspective(img2, H2, (w2, h2))\n","\n","# Tracer les droites épipolaires sur les images rectifiées avec correspondance de couleur correcte\n","imgL_rect_corr, imgR_rect_corr = draw_corrected_epilines(img1_rectified_corr, img2_rectified_corr, inlierpts1, inlierpts2, FRansac)\n","\n","# Affichage des images rectifiées avec épilines corrigées\n","plt.figure(figsize=(15, 5))\n","plt.subplot(121), plt.imshow(imgL_rect_corr, cmap='gray')\n","plt.title('Image gauche rectifiée avec épilines corrigées')\n","plt.subplot(122), plt.imshow(imgR_rect_corr, cmap='gray')\n","plt.title('Image droite rectifiée avec épilines corrigées')\n","plt.show()\n","\n"],"metadata":{"id":"KtqNBrMJhRtM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from google.colab.patches import cv2_imshow\n","import cv2\n","import matplotlib.pyplot as plt\n","\n","# Charger les images gauche et droite en niveaux de gris\n","imgLeft = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imLeft.png', 0)\n","imgRight = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imRight.png', 0)\n","\n","# Initialiser l'objet de correspondance stéréo\n","stereo = cv2.StereoBM_create(numDisparities=16, blockSize=5)\n","\n","# Calculer l'image de disparité\n","disparity = stereo.compute(imgLeft, imgRight)\n","\n","# Normaliser l'image pour la représentation\n","min_disp = disparity.min()\n","max_disp = disparity.max()\n","disparity = np.uint8(255 * (disparity - min_disp) / (max_disp - min_disp))\n","\n","# Afficher les résultats côte à côte\n","plt.figure(figsize=(20,10))\n","\n","plt.subplot(1, 3, 1)\n","plt.title('Image I(x,y)')\n","plt.imshow(imgLeft, cmap='gray')\n","\n","plt.subplot(1, 3, 2)\n","plt.title('Carte des disparités D(x,y)')\n","plt.imshow(disparity, cmap='gray')\n","\n","plt.subplot(1, 3, 3)\n","plt.title(\"Image I'(x', y')\")\n","plt.imshow(imgRight, cmap='gray')\n","\n","plt.show()\n"],"metadata":{"id":"jJN57-as46IR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","from google.colab.patches import cv2_imshow\n","import cv2\n","import matplotlib.pyplot as plt\n","\n","# Charger les images gauche et droite en niveaux de gris\n","imgLeft = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imLeft.png', 0)\n","imgRight = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imRight.png', 0)\n","\n","# Initialiser l'objet de correspondance stéréo\n","stereo = cv2.StereoBM_create(numDisparities=64, blockSize=5)\n","\n","# Calculer l'image de disparité\n","disparity = stereo.compute(imgLeft, imgRight)\n","\n","# Normaliser l'image pour la représentation\n","min_disp = disparity.min()\n","max_disp = disparity.max()\n","disparity = np.uint8(255 * (disparity - min_disp) / (max_disp - min_disp))\n","\n","# Afficher les résultats côte à côte\n","plt.figure(figsize=(20,10))\n","\n","plt.subplot(1, 3, 1)\n","plt.title('Image I(x,y)')\n","plt.imshow(imgLeft, cmap='gray')\n","\n","plt.subplot(1, 3, 2)\n","plt.title('Carte des disparités D(x,y)')\n","plt.imshow(disparity, cmap='gray')\n","\n","plt.subplot(1, 3, 3)\n","plt.title(\"Image I'(x', y')\")\n","plt.imshow(imgRight, cmap='gray')\n","\n","plt.show()\n"],"metadata":{"id":"7PemQFuYEPfx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","# Lecture des deux images\n","imgL = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imLeft.png', cv2.IMREAD_GRAYSCALE)  # Image gauche\n","imgR = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imRight.png', cv2.IMREAD_GRAYSCALE)  # Image droite\n","\n","# Détection des points d'intérêt\n","sift = cv2.SIFT_create()\n","kpL, desL = sift.detectAndCompute(imgL, None)\n","kpR, desR = sift.detectAndCompute(imgR, None)\n","\n","# Correspondances des points\n","bf = cv2.BFMatcher()\n","matches = bf.knnMatch(desL, desR, k=2)\n","\n","# Appliquer le ratio test de Lowe pour filtrer les bonnes correspondances\n","good = []\n","for m, n in matches:\n","    if m.distance < 0.75 * n.distance:\n","        good.append(m)\n","\n","# Trier les correspondances par distance\n","good = sorted(good, key=lambda x: x.distance)\n","# Conserver les 100 correspondances les plus fortes\n","strong_matches = good[:187]\n","\n","# Préparer les points pour dessiner les lignes\n","ptsL = np.float32([kpL[m.queryIdx].pt for m in strong_matches])\n","ptsR = np.float32([kpR[m.trainIdx].pt for m in strong_matches])\n","\n","# Dessiner les correspondances les plus fortes sur l'image gauche\n","output_img = cv2.cvtColor(imgL, cv2.COLOR_GRAY2BGR)\n","for ptL, ptR in zip(ptsL, ptsR):\n","    ptL = (int(ptL[0]), int(ptL[1]))\n","    ptR = (int(ptR[0]), int(ptR[1]))\n","    # Ajuster la longueur des lignes pour qu'elles soient plus courtes et dirigées vers la droite\n","    line_length = 20\n","    direction = (line_length, 0)  # Direction vers la droite\n","    end_point = (ptL[0] + direction[0], ptL[1] + direction[1])\n","    output_img = cv2.circle(output_img, ptL, 5, (255, 0, 255), -1)  # Points en jaune\n","    output_img = cv2.line(output_img, ptL, end_point, (255, 0, 255), 2)  # Lignes en jaune\n","\n","# Affichage de l'image avec les correspondances\n","plt.figure(figsize=(10, 7))\n","plt.imshow(output_img)\n","plt.title('Correspondances les plus fortes (187) - Image gauche')\n","plt.axis('off')\n","plt.show()\n"],"metadata":{"id":"C54uPlkL5LFH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dessiner les correspondances les plus fortes entre les deux images\n","output_img_full = cv2.drawMatches(imgL, kpL, imgR, kpR, strong_matches, None, flags=cv2.DrawMatchesFlags_NOT_DRAW_SINGLE_POINTS)\n","\n","# Affichage de l'image avec les correspondances complètes\n","plt.figure(figsize=(15, 10))\n","plt.imshow(output_img_full)\n","plt.title('Correspondances les plus fortes (100) - Image gauche et droite')\n","plt.axis('off')\n","plt.show()\n"],"metadata":{"id":"pKLQECib5OzY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Calcul de la matrice fondamentale avec OpenCV RANSAC\n","F, mask = cv2.findFundamentalMat(ptsL, ptsR, cv2.FM_RANSAC)\n","\n","# Filtrer les points inliers\n","ptsL = ptsL[mask.ravel() == 1]\n","ptsR = ptsR[mask.ravel() == 1]\n","\n","# Calcul des droites épipolaires\n","def drawlines(img1, img2, lines, pts1, pts2):\n","    ''' img1 - image sur laquelle on dessine les épilines pour les points dans img2\n","        lines - épilines correspondantes '''\n","    r, c = img1.shape\n","    img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n","    img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n","    for r, pt1, pt2 in zip(lines, pts1, pts2):\n","        color = tuple(np.random.randint(0, 255, 3).tolist())\n","        x0, y0 = map(int, [0, -r[2] / r[1]])\n","        x1, y1 = map(int, [c, -(r[2] + r[0] * c) / r[1]])\n","        img1 = cv2.line(img1, (x0, y0), (x1, y1), color, 1)\n","        img1 = cv2.circle(img1, (int(pt1[0]), int(pt1[1])), 3, color, -1)\n","        img2 = cv2.circle(img2, (int(pt2[0]), int(pt2[1])), 3, color, -1)\n","    return img1, img2\n","\n","# Calculer les droites épipolaires pour chaque image\n","lines1 = cv2.computeCorrespondEpilines(ptsR.reshape(-1, 1, 2), 2, F)\n","lines1 = lines1.reshape(-1, 3)\n","lines2 = cv2.computeCorrespondEpilines(ptsL.reshape(-1, 1, 2), 1, F)\n","lines2 = lines2.reshape(-1, 3)\n","\n","imgL_lines, imgR_lines = drawlines(imgL, imgR, lines1, ptsL, ptsR)\n","imgR_lines, imgL_lines = drawlines(imgR, imgL, lines2, ptsR, ptsL)\n","\n","# Affichage des images avec les lignes épipolaires\n","plt.figure(figsize=(15, 5))\n","plt.subplot(121), plt.imshow(imgL_lines)\n","plt.title('Lignes épipolaires - Image gauche')\n","plt.subplot(122), plt.imshow(imgR_lines)\n","plt.title('Lignes épipolaires - Image droite')\n","plt.show()\n"],"metadata":{"id":"Yp9g_JzJ6ODB"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Assurez-vous que les deux images ont la même taille\n","height, width = imgL.shape\n","if imgR.shape != imgL.shape:\n","    imgR = cv2.resize(imgR, (width, height))\n","\n","# Calcul de la carte de disparité avec StereoSGBM\n","min_disp = 0\n","num_disp = 16*3  # Doit être multiple de 16\n","block_size = 5\n","\n","stereo = cv2.StereoSGBM_create(minDisparity=min_disp,\n","    numDisparities=num_disp,\n","    blockSize=block_size,\n","    P1=8 * 3 * block_size ** 2,\n","    P2=32 * 3 * block_size ** 2,\n","    disp12MaxDiff=1,\n","    uniquenessRatio=10,\n","    speckleWindowSize=100,\n","    speckleRange=32,\n","    preFilterCap=63,\n","    mode=cv2.STEREO_SGBM_MODE_SGBM_3WAY)\n","\n","disparity = stereo.compute(imgL, imgR).astype(np.float32) / 16.0\n","\n","# Normaliser la disparité pour l'afficher correctement\n","disparity = (disparity - min_disp) / num_disp\n","\n","# Appliquer une colormap pour mieux visualiser la disparité\n","disparity_colormap = cv2.applyColorMap((disparity * 255).astype(np.uint8), cv2.COLORMAP_JET)\n","\n","# Affichage de la carte de disparité\n","plt.figure(figsize=(10, 5))\n","plt.title(\"Carte de Disparité\")\n","plt.imshow(disparity_colormap)\n","plt.colorbar()\n","plt.show()\n"],"metadata":{"id":"9yk0CnWN6cDI"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Conversion de la disparité en profondeur\n","focal_length = 0.2  # Longueur focale de la caméra (ajustez selon votre configuration)\n","baseline = 0.2  # Distance entre les caméras (en mètres, ajustez selon votre configuration)\n","depth = (focal_length * baseline) / (disparity + 1e-6)  # Ajouter une petite valeur pour éviter la division par zéro\n","\n","# Affichage de la carte de profondeur\n","plt.figure(figsize=(10, 5))\n","plt.title(\"Carte de Profondeur\")\n","plt.imshow(depth, cmap='gray')\n","plt.colorbar()\n","plt.show()\n"],"metadata":{"id":"DieEGg716kkj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","# Lecture des deux images\n","imgL = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imLeft.png', cv2.IMREAD_GRAYSCALE)  # Image gauche\n","imgR = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imRight.png', cv2.IMREAD_GRAYSCALE)  # Image droite\n","\n","# Détection des points d'intérêt\n","sift = cv2.SIFT_create()\n","kpL, desL = sift.detectAndCompute(imgL, None)\n","kpR, desR = sift.detectAndCompute(imgR, None)\n","\n","# Correspondances des points\n","bf = cv2.BFMatcher()\n","matches = bf.knnMatch(desL, desR, k=2)\n","\n","# Appliquer le ratio test de Lowe pour filtrer les bonnes correspondances\n","good = []\n","for m, n in matches:\n","    if m.distance < 0.75 * n.distance:\n","        good.append(m)\n","\n","# Trier les correspondances par distance\n","good = sorted(good, key=lambda x: x.distance)\n","# Conserver les 100 correspondances les plus fortes\n","strong_matches = good[:100]\n","\n","# Préparer les points pour dessiner les lignes\n","ptsL = np.float32([kpL[m.queryIdx].pt for m in strong_matches])\n","ptsR = np.float32([kpR[m.trainIdx].pt for m in strong_matches])\n","\n","# Dessiner les correspondances les plus fortes sur l'image gauche\n","output_img_left = cv2.cvtColor(imgL, cv2.COLOR_GRAY2BGR)\n","for ptL, ptR in zip(ptsL, ptsR):\n","    ptL = (int(ptL[0]), int(ptL[1]))\n","    ptR = (int(ptR[0]), int(ptR[1]))\n","    # Ajuster la longueur des lignes pour qu'elles soient plus courtes et dirigées vers la droite\n","    line_length = 20\n","    direction = (line_length, 0)  # Direction vers la droite\n","    end_point = (ptL[0] + direction[0], ptL[1] + direction[1])\n","    output_img_left = cv2.circle(output_img_left, ptL, 5, (100, 0, 255), -1)  # Points en jaune\n","    output_img_left = cv2.line(output_img_left, ptL, end_point, (100, 0, 255), 2)  # Lignes en jaune\n","\n","# Dessiner les points correspondants sur l'image droite\n","output_img_right = cv2.cvtColor(imgR, cv2.COLOR_GRAY2BGR)\n","for pt in ptsR:\n","    pt = (int(pt[0]), int(pt[1]))\n","    output_img_right = cv2.circle(output_img_right, pt, 5, (100, 0, 255), -1)  # Points en jaune\n","\n","# Affichage des images originales et des correspondances\n","fig, axs = plt.subplots(2, 2, figsize=(12, 12))\n","\n","# Afficher l'image gauche originale\n","axs[0, 0].imshow(cv2.cvtColor(imgL, cv2.COLOR_GRAY2RGB))\n","axs[0, 0].set_title('Image gauche originale')\n","axs[0, 0].axis('on')  # Activer les axes\n","axs[0, 0].grid(False)\n","\n","# Afficher l'image droite originale\n","axs[0, 1].imshow(cv2.cvtColor(imgR, cv2.COLOR_GRAY2RGB))\n","axs[0, 1].set_title('Image droite originale')\n","axs[0, 1].axis('on')  # Activer les axes\n","axs[0, 1].grid(False)\n","\n","# Afficher l'image gauche avec les lignes courtes\n","axs[1, 0].imshow(output_img_left)\n","axs[1, 0].set_title('Correspondances les plus fortes (100) - Image gauche')\n","axs[1, 0].axis('on')  # Activer les axes\n","axs[1, 0].grid(False)\n","\n","# Afficher l'image droite avec les points correspondants\n","axs[1, 1].imshow(output_img_right)\n","axs[1, 1].set_title('Points correspondants - Image droite')\n","axs[1, 1].axis('on')  # Activer les axes\n","axs[1, 1].grid(False)\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"QDzIrT19-GPH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import math\n","import copy\n","from tqdm import tqdm\n","\n","# Function to perform preprocessing operations on the images\n","def preprocessing(img):\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    processed_img = cv2.GaussianBlur(gray, (15,15), 0)\n","    return processed_img\n","\n","# Function to find features in the two images\n","def feature_detection(img1, img2):\n","    processed_img1, processed_img2 = preprocessing(img1), preprocessing(img2)\n","    sift = cv2.SIFT_create()\n","    kp1, desc1 = sift.detectAndCompute(processed_img1, None)\n","    kp2, desc2 = sift.detectAndCompute(processed_img2, None)\n","    bf = cv2.BFMatcher()\n","    matches = bf.knnMatch(desc1, desc2, k=2)\n","\n","    # Extracting good matches\n","    good = []\n","    for m, n in matches:\n","        if m.distance < 0.2 * n.distance:\n","            good.append([m])\n","\n","    left_pts = np.float32([kp1[m[0].queryIdx].pt for m in good])\n","    right_pts = np.float32([kp2[m[0].trainIdx].pt for m in good])\n","    return left_pts, right_pts\n","\n","# Function to compute Fundamental Matrix given feature points in two images\n","def fundamental_matrix(left_pts, right_pts):\n","    A = []\n","\n","    for i in range(8):\n","        src_x, src_y = left_pts[i]\n","        dst_x, dst_y = right_pts[i]\n","        A_row = np.asarray([dst_x * src_x, dst_x * src_y, dst_x, dst_y * src_x, dst_y * src_y, dst_y, src_x, src_y, 1])\n","        A.append(A_row)\n","\n","    A = np.asarray(A)\n","    U, S, V = np.linalg.svd(A)\n","    F = np.reshape(V[-1, :], (3, 3))\n","    u, s, vt = np.linalg.svd(F)\n","    s = np.diag(s)\n","    s[2, 2] = 0\n","    F = u @ (s @ vt)\n","    F = F / F[-1, -1]\n","    F = (abs(F) > (10 ** (-3))) * F\n","    return F\n","\n","# RANSAC function to find the best Fundamental Matrix that satisfies the epipolar constraint\n","def ransac(src_pts, dst_pts, iterations, threshold):\n","    number_of_points = len(src_pts)\n","    max_inlier_count = 0\n","\n","    for _ in range(iterations):\n","        inlier = 0\n","        random_indices = np.random.choice(number_of_points, size=8, replace=False)\n","        random_src_pts = src_pts[random_indices, :]\n","        random_dst_pts = dst_pts[random_indices, :]\n","\n","        F = fundamental_matrix(random_src_pts, random_dst_pts)\n","\n","        for i in range(number_of_points):\n","            a, b = dst_pts[i], src_pts[i]\n","            a, b = np.append(a, 1).reshape((3, 1)), np.append(b, 1).reshape((3, 1))\n","            c = (a.T @ F) @ b\n","\n","            if abs(c) <= threshold:\n","                inlier += 1\n","\n","        if inlier > max_inlier_count:\n","            max_inlier_count = inlier\n","            best_F = F\n","    return best_F\n","\n","# Function to compute essential matrix\n","def essential_matrix(F, K1, K2):\n","    E = (K2.T @ F) @ K1\n","    U, _, V = np.linalg.svd(E)\n","    S = [1, 1, 0]\n","    S = np.diag(S)\n","    E = np.matmul(np.matmul(U, S), V)\n","    return E\n","\n","# Function to decompose Essential Matrix to find Rotation and Translation\n","def decompose_essential_matrix(E):\n","    W = np.array([[0, -1, 0], [1, 0, 0], [0, 0, 1]])\n","    U, S, V = np.linalg.svd(E)\n","\n","    R_set = []\n","    C_set = []\n","\n","    R_set.append((U @ W) @ V)\n","    R_set.append((U @ W) @ V)\n","    R_set.append((U @ W.T) @ V)\n","    R_set.append((U @ W.T) @ V)\n","    C_set.append(U[:, 2])\n","    C_set.append(-U[:, 2])\n","    C_set.append(U[:, 2])\n","    C_set.append(-U[:, 2])\n","\n","    for i in range(4):\n","        if (np.linalg.det(R_set[i]) < 0):\n","            R_set[i] = -R_set[i]\n","            C_set[i] = -C_set[i]\n","\n","    return R_set, C_set\n","\n","# Function to find the Projection Matrix\n","def projection_matrix(K, R, C):\n","    I = np.identity(3)\n","    C = np.reshape(C, (3, 1))\n","    return (K @ (R @ np.hstack((I, -C))))\n","\n","# Function to find 3D point given 2D pixel locations\n","def linear_triangulation(R_set, C_set, left_pts, right_pts, K1, K2):\n","    x3D_set = []\n","\n","    for i in range(len(R_set)):\n","        R1, R2 = np.identity(3), R_set[i]\n","        C1, C2 = np.zeros((3, 1)), C_set[i].reshape(3, 1)\n","\n","        P1 = projection_matrix(K1, R1, C1)\n","        P2 = projection_matrix(K2, R2, C2)\n","\n","        p1, p2, p3 = P1\n","        p1_, p2_, p3_ = P2\n","\n","        p1, p2, p3 = p1.reshape(1, -1), p2.reshape(1, -1), p3.reshape(1, -1)\n","        p1_, p2_, p3_ = p1_.reshape(1, -1), p2_.reshape(1, -1), p3_.reshape(1, -1)\n","\n","        x3D = []\n","\n","        for left_pt, right_pt in zip(left_pts, right_pts):\n","            x, y = left_pt\n","            x_, y_ = right_pt\n","            A = np.vstack((y * p3 - p2, p1 - x * p3, y_ * p3_ - p2_, p1_ - x_ * p3_))\n","            _, _, Vt = np.linalg.svd(A)\n","            X = Vt[-1]\n","            X = X / X[-1]\n","            x3D.append(X[:3])\n","\n","        x3D_set.append(x3D)\n","    return x3D_set\n","\n","# Function to find best camera pose configuration out of the four options\n","def disambiguate_camera_pose(R_set, C_set, x3D_set):\n","    best_i = 0\n","    max_positive_depths = 0\n","\n","    for i in range(len(R_set)):\n","        n_positive_depths = 0\n","        R, C = R_set[i], C_set[i].reshape(-1, 1)\n","        r3 = R[2].reshape(1, -1)\n","        x3D = x3D_set[i]\n","\n","        for X in x3D:\n","            X = X.reshape(-1, 1)\n","            if r3 @ (X - C) > 0 and X[2] > 0:\n","                n_positive_depths += 1\n","\n","        if n_positive_depths > max_positive_depths:\n","            best_i = i\n","            max_positive_depths = n_positive_depths\n","\n","    R, C = R_set[best_i], C_set[best_i]\n","    return R, C\n","\n","# Function to find start and end co-ordinates given equation of an epiline\n","def epiline_coordinates(lines, img):\n","    lines = lines.reshape(-1, 3)\n","    c = img.shape[1]\n","    co_ordinates = []\n","\n","    for line in lines:\n","        x0, y0 = map(int, [0, -line[2] / line[1]])\n","        x1, y1 = map(int, [c, -(line[2] + line[0] * c) / line[1]])\n","        co_ordinates.append([[x0, y0], [x1, y1]])\n","\n","    return co_ordinates\n","\n","# Function to draw epilines on the two corresponding images\n","# Continue drawing epilines on the two corresponding images\n","def draw_epilines(l_epiline_coords, r_epiline_coords, left_pts, right_pts, img1, img2):\n","    img1_copy = copy.deepcopy(img1)\n","    img2_copy = copy.deepcopy(img2)\n","\n","    for l_epiline_coord, r_epiline_coord, left_pt, right_pt in zip(l_epiline_coords, r_epiline_coords, np.int32(left_pts), np.int32(right_pts)):\n","        color = tuple(np.random.randint(0,255,3).tolist())\n","        img1_copy = cv2.line(img1_copy, l_epiline_coord[0], l_epiline_coord[1], color, 2)\n","        img1_copy = cv2.circle(img1_copy, (left_pt[0], left_pt[1]), 7, color, -1)\n","        img2_copy = cv2.line(img2_copy, r_epiline_coord[0], r_epiline_coord[1], color, 2)\n","        img2_copy = cv2.circle(img2_copy, (right_pt[0], right_pt[1]), 7, color, -1)\n","\n","    return img1_copy, img2_copy\n","\n","# Load images\n","img1 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imLeft.png')\n","img2 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imRight.png')\n","\n","# Detect features and compute fundamental matrix using RANSAC\n","left_pts, right_pts = feature_detection(img1, img2)\n","F = ransac(left_pts, right_pts, 1500, 0.02)\n","\n","# Compute essential matrix and decompose it to find rotation and translation\n","K1 = np.array([[1758.23, 0, 977.42], [0, 1758.23, 552.15], [0, 0, 1]])\n","K2 = np.array([[1758.23, 0, 977.42], [0, 1758.23, 552.15], [0, 0, 1]])\n","E = essential_matrix(F, K1, K2)\n","R_set, C_set = decompose_essential_matrix(E)\n","x3D_set = linear_triangulation(R_set, C_set, left_pts, right_pts, K1, K2)\n","R, T = disambiguate_camera_pose(R_set, C_set, x3D_set)\n","\n","# Compute epilines\n","l_epilines = cv2.computeCorrespondEpilines(right_pts.reshape(-1, 1, 2), 2, F)\n","r_epilines = cv2.computeCorrespondEpilines(left_pts.reshape(-1, 1, 2), 1, F)\n","l_epiline_coords = epiline_coordinates(l_epilines, img1)\n","r_epiline_coords = epiline_coordinates(r_epilines, img2)\n","\n","# Draw epilines on the images\n","img1_with_epilines, img2_with_epilines = draw_epilines(l_epiline_coords, r_epiline_coords, left_pts, right_pts, img1, img2)\n","\n","# Display the images with epilines\n","plt.figure(figsize=(15, 10))\n","plt.subplot(121), plt.imshow(cv2.cvtColor(img1_with_epilines, cv2.COLOR_BGR2RGB))\n","plt.title('Lignes épipolaires - Image gauche')\n","plt.subplot(122), plt.imshow(cv2.cvtColor(img2_with_epilines, cv2.COLOR_BGR2RGB))\n","plt.title('Lignes épipolaires - Image droite')\n","plt.show()\n","\n","# Stereo Rectification\n","h1, w1 = img1.shape[:2]\n","_, H1, H2 = cv2.stereoRectifyUncalibrated(np.float32(left_pts), np.float32(right_pts), F, imgSize=(w1, h1))\n","\n","# Rectify the images\n","img1_rectified = cv2.warpPerspective(img1, H1, (w1, h1))\n","img2_rectified = cv2.warpPerspective(img2, H2, (w1, h1))\n","\n","# Compute disparity map\n","a_gray = cv2.cvtColor(img1_rectified, cv2.COLOR_BGR2GRAY)\n","b_gray = cv2.cvtColor(img2_rectified, cv2.COLOR_BGR2GRAY)\n","a_gray = a_gray.astype(float)\n","b_gray = b_gray.astype(float)\n","h, w = a_gray.shape\n","\n","disparity_map = np.zeros((h, w))\n","BLOCK_SIZE = 7\n","SEARCH_BLOCK_SIZE = 56\n","\n","for y in tqdm(range(BLOCK_SIZE, h - BLOCK_SIZE)):\n","    for x in range(BLOCK_SIZE, w - BLOCK_SIZE):\n","        block_left = a_gray[y:y + BLOCK_SIZE, x:x + BLOCK_SIZE]\n","        min_index = compare_blocks(y, x, block_left, b_gray, BLOCK_SIZE, SEARCH_BLOCK_SIZE)\n","        disparity_map[y, x] = abs(min_index[1] - x)\n","\n","disparity = np.uint8(disparity_map * 255 / np.max(disparity_map))\n","heatmap_disparity = cv2.applyColorMap(disparity, cv2.COLORMAP_JET)\n","\n","# Compute depth map\n","f = K1[0, 0]\n","baseline = 88.39\n","depth = (baseline * f) / (disparity + 1e-15)\n","depth[depth > 30000] = 30000\n","depth_map = np.uint8(depth * 255 / np.max(depth))\n","heatmap_depth = cv2.applyColorMap(depth_map, cv2.COLORMAP_JET)\n","\n","# Display the rectified images, disparity map, and depth map\n","plt.figure(figsize=(20, 10))\n","\n","# Display rectified images\n","plt.subplot(2, 3, 1)\n","plt.imshow(cv2.cvtColor(img1_rectified, cv2.COLOR_BGR2RGB))\n","plt.title('Image gauche rectifiée')\n","plt.axis('on')\n","plt.grid(True)\n","\n","plt.subplot(2, 3, 2)\n","plt.imshow(cv2.cvtColor(img2_rectified, cv2.COLOR_BGR2RGB))\n","plt.title('Image droite rectifiée')\n","plt.axis('on')\n","plt.grid(True)\n","\n","# Display disparity map\n","plt.subplot(2, 3, 3)\n","plt.imshow(heatmap_disparity)\n","plt.title('Carte de disparité')\n","plt.colorbar()\n","plt.axis('on')\n","plt.grid(True)\n","\n","# Display depth map\n","plt.subplot(2, 3, 4)\n","plt.imshow(heatmap_depth)\n","plt.title('Carte de profondeur')\n","plt.colorbar()\n","plt.axis('on')\n","plt.grid(True)\n","\n","plt.tight_layout()\n","plt.show()\n"],"metadata":{"id":"Gq6aJ9k1B-DM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import copy\n","from tqdm import tqdm\n","\n","# Function to perform preprocessing operations on the images\n","def preprocessing(img):\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    processed_img = cv2.GaussianBlur(gray, (15, 15), 0)\n","    return processed_img\n","\n","# Function to find features in the two images\n","def feature_detection(img1, img2):\n","    processed_img1, processed_img2 = preprocessing(img1), preprocessing(img2)\n","    sift = cv2.SIFT_create()\n","    kp1, desc1 = sift.detectAndCompute(processed_img1, None)\n","    kp2, desc2 = sift.detectAndCompute(processed_img2, None)\n","    bf = cv2.BFMatcher()\n","    matches = bf.knnMatch(desc1, desc2, k=2)\n","\n","    # Extracting good matches\n","    good = []\n","    for m, n in matches:\n","        if m.distance < 0.5 * n.distance:\n","            good.append([m])\n","\n","    left_pts = np.float32([kp1[m[0].queryIdx].pt for m in good])\n","    right_pts = np.float32([kp2[m[0].trainIdx].pt for m in good])\n","    return left_pts, right_pts, kp1, kp2, good\n","\n","# Function to compute Fundamental Matrix given feature points in two images\n","def fundamental_matrix(left_pts, right_pts):\n","    A = []\n","\n","    for i in range(8):\n","        src_x, src_y = left_pts[i]\n","        dst_x, dst_y = right_pts[i]\n","        A_row = np.asarray([dst_x * src_x, dst_x * src_y, dst_x, dst_y * src_x, dst_y * src_y, dst_y, src_x, src_y, 1])\n","        A.append(A_row)\n","\n","    A = np.asarray(A)\n","    U, S, V = np.linalg.svd(A)\n","    F = np.reshape(V[-1, :], (3, 3))\n","    u, s, vt = np.linalg.svd(F)\n","    s = np.diag(s)\n","    s[2, 2] = 0\n","    F = u @ (s @ vt)\n","    F = F / F[-1, -1]\n","    F = (abs(F) > (10 ** (-3))) * F\n","    return F\n","\n","# RANSAC function to find the best Fundamental Matrix that satisfies the epipolar constraint\n","def ransac(src_pts, dst_pts, iterations, threshold):\n","    number_of_points = len(src_pts)\n","    max_inlier_count = 0\n","\n","    for _ in range(iterations):\n","        inlier = 0\n","        random_indices = np.random.choice(number_of_points, size=8, replace=False)\n","        random_src_pts = src_pts[random_indices, :]\n","        random_dst_pts = dst_pts[random_indices, :]\n","\n","        F = fundamental_matrix(random_src_pts, random_dst_pts)\n","\n","        for i in range(number_of_points):\n","            a, b = dst_pts[i], src_pts[i]\n","            a, b = np.append(a, 1).reshape((3, 1)), np.append(b, 1).reshape((3, 1))\n","            c = (a.T @ F) @ b\n","\n","            if abs(c) <= threshold:\n","                inlier += 1\n","\n","        if inlier > max_inlier_count:\n","            max_inlier_count = inlier\n","            best_F = F\n","    return best_F\n","\n","# Function to compute essential matrix\n","def essential_matrix(F, K1, K2):\n","    E = (K2.T @ F) @ K1\n","    U, _, V = np.linalg.svd(E)\n","    S = [1, 1, 0]\n","    S = np.diag(S)\n","    E = np.matmul(np.matmul(U, S), V)\n","    return E\n","\n","# Function to decompose Essential Matrix to find Rotation and Translation\n","def decompose_essential_matrix(E):\n","    W = np.array([[0, -1, 0], [1, 0, 0], [0, 0, 1]])\n","    U, S, V = np.linalg.svd(E)\n","\n","    R_set = []\n","    C_set = []\n","\n","    R_set.append((U @ W) @ V)\n","    R_set.append((U @ W) @ V)\n","    R_set.append((U @ W.T) @ V)\n","    R_set.append((U @ W.T) @ V)\n","    C_set.append(U[:, 2])\n","    C_set.append(-U[:, 2])\n","    C_set.append(U[:, 2])\n","    C_set.append(-U[:, 2])\n","\n","    for i in range(4):\n","        if (np.linalg.det(R_set[i]) < 0):\n","            R_set[i] = -R_set[i]\n","            C_set[i] = -C_set[i]\n","\n","    return R_set, C_set\n","\n","# Function to find the Projection Matrix\n","def projection_matrix(K, R, C):\n","    I = np.identity(3)\n","    C = np.reshape(C, (3, 1))\n","    return (K @ (R @ np.hstack((I, -C))))\n","\n","# Function to find 3D point given 2D pixel locations\n","def linear_triangulation(R_set, C_set, left_pts, right_pts, K1, K2):\n","    x3D_set = []\n","\n","    for i in range(len(R_set)):\n","        R1, R2 = np.identity(3), R_set[i]\n","        C1, C2 = np.zeros((3, 1)), C_set[i].reshape(3, 1)\n","\n","        P1 = projection_matrix(K1, R1, C1)\n","        P2 = projection_matrix(K2, R2, C2)\n","\n","        p1, p2, p3 = P1\n","        p1_, p2_, p3_ = P2\n","\n","        p1, p2, p3 = p1.reshape(1, -1), p2.reshape(1, -1), p3.reshape(1, -1)\n","        p1_, p2_, p3_ = p1_.reshape(1, -1), p2_.reshape(1, -1), p3_.reshape(1, -1)\n","\n","        x3D = []\n","\n","        for left_pt, right_pt in zip(left_pts, right_pts):\n","            x, y = left_pt\n","            x_, y_ = right_pt\n","            A = np.vstack((y * p3 - p2, p1 - x * p3, y_ * p3_ - p2_, p1_ - x_ * p3_))\n","            _, _, Vt = np.linalg.svd(A)\n","            X = Vt[-1]\n","            X = X / X[-1]\n","            x3D.append(X[:3])\n","\n","        x3D_set.append(x3D)\n","    return x3D_set\n","\n","# Function to find best camera pose configuration out of the four options\n","def disambiguate_camera_pose(R_set, C_set, x3D_set):\n","    best_i = 0\n","    max_positive_depths = 0\n","\n","    for i in range(len(R_set)):\n","        n_positive_depths = 0\n","        R, C = R_set[i], C_set[i].reshape(-1, 1)\n","        r3 = R[2].reshape(1, -1)\n","        x3D = x3D_set[i]\n","\n","        for X in x3D:\n","            X = X.reshape(-1, 1)\n","            if r3 @ (X - C) > 0 and X[2] > 0:\n","                n_positive_depths += 1\n","\n","        if n_positive_depths > max_positive_depths:\n","            best_i = i\n","            max_positive_depths = n_positive_depths\n","\n","    R, C = R_set[best_i], C_set[best_i]\n","    return R, C\n","\n","# Function to find start and end coordinates given equation of an epiline\n","def epiline_coordinates(lines, img):\n","    lines = lines.reshape(-1, 3)\n","    c = img.shape[1]\n","    coordinates = []\n","\n","    for line in lines:\n","        x0, y0 = map(int, [0, -line[2] / line[1]])\n","        x1, y1 = map(int, [c, -(line[2] + line[0] * c) / line[1]])\n","        coordinates.append([[x0, y0], [x1, y1]])\n","\n","    return coordinates\n","\n","# Function to draw epilines on the two corresponding images\n","def draw_epilines(l_epiline_coords, r_epiline_coords, left_pts, right_pts, img1, img2):\n","    img1_copy = copy.deepcopy(img1)\n","    img2_copy = copy.deepcopy(img2)\n","\n","    for l_epiline_coord, r_epiline_coord, left_pt, right_pt in zip(l_epiline_coords, r_epiline_coords, np.int32(left_pts), np.int32(right_pts)):\n","        color = tuple(np.random.randint(0, 255, 3).tolist())\n","        img1_copy = cv2.line(img1_copy, l_epiline_coord[0], l_epiline_coord[1], color, 2)\n","        img1_copy = cv2.circle(img1_copy, (left_pt[0], left_pt[1]), 7, color, -1)\n","        img2_copy = cv2.line(img2_copy, r_epiline_coord[0], r_epiline_coord[1], color, 2)\n","        img2_copy = cv2.circle(img2_copy, (right_pt[0], right_pt[1]), 7, color, -1)\n","\n","    return img1_copy, img2_copy\n","\n","# Load images\n","img1 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imLeft.png')\n","img2 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imRight.png')\n","\n","# Detect features and compute fundamental matrix using RANSAC\n","left_pts, right_pts, kp1, kp2, good = feature_detection(img1, img2)\n","F = ransac(left_pts, right_pts, 1500, 0.02)\n","\n","# Compute essential matrix and decompose it to find rotation and translation\n","K1 = np.array([[1758.23, 0, 977.42], [0, 1758.23, 552.15], [0, 0, 1]])\n","K2 = np.array([[1758.23, 0, 977.42], [0, 1758.23, 552.15], [0, 0, 1]])\n","E = essential_matrix(F, K1, K2)\n","R_set, C_set = decompose_essential_matrix(E)\n","x3D_set = linear_triangulation(R_set, C_set, left_pts, right_pts, K1, K2)\n","R, T = disambiguate_camera_pose(R_set, C_set, x3D_set)\n","\n","# Compute epilines\n","l_epilines = cv2.computeCorrespondEpilines(right_pts.reshape(-1, 1, 2), 2, F)\n","r_epilines = cv2.computeCorrespondEpilines(left_pts.reshape(-1, 1, 2), 1, F)\n","l_epiline_coords = epiline_coordinates(l_epilines, img1)\n","r_epiline_coords = epiline_coordinates(r_epilines, img2)\n","\n","# Draw epilines on the images\n","img1_with_epilines, img2_with_epilines = draw_epilines(l_epiline_coords, r_epiline_coords, left_pts, right_pts, img1, img2)\n","\n","# Concatenate images horizontally for display\n","img_pair_with_epilines = np.hstack((img1_with_epilines, img2_with_epilines))\n","\n","# Display the images with epilines\n","plt.figure(figsize=(15, 10))\n","plt.imshow(cv2.cvtColor(img_pair_with_epilines, cv2.COLOR_BGR2RGB))\n","plt.title('Epipolar lines corresponding to the obtained matching features')\n","plt.axis('off')\n","plt.show()\n","\n","# Stereo Rectification\n","h1, w1 = img1.shape[:2]\n","_, H1, H2 = cv2.stereoRectifyUncalibrated(np.float32(left_pts), np.float32(right_pts), F, imgSize=(w1, h1))\n","\n","# Rectify the images\n","img1_rectified = cv2.warpPerspective(img1, H1, (w1, h1))\n","img2_rectified = cv2.warpPerspective(img2, H2, (w1, h1))\n","\n","# Compute rectified epilines\n","l_epilines_rect = cv2.computeCorrespondEpilines(right_pts.reshape(-1, 1, 2), 2, F)\n","r_epilines_rect = cv2.computeCorrespondEpilines(left_pts.reshape(-1, 1, 2), 1, F)\n","l_epiline_coords_rect = epiline_coordinates(l_epilines_rect, img1_rectified)\n","r_epiline_coords_rect = epiline_coordinates(r_epilines_rect, img2_rectified)\n","\n","# Draw epilines on the rectified images\n","img1_with_epilines_rect, img2_with_epilines_rect = draw_epilines(l_epiline_coords_rect, r_epiline_coords_rect, left_pts, right_pts, img1_rectified, img2_rectified)\n","\n","# Concatenate rectified images horizontally for display\n","img_pair_with_epilines_rect = np.hstack((img1_with_epilines_rect, img2_with_epilines_rect))\n","\n","# Display the rectified images with epilines\n","plt.figure(figsize=(15, 10))\n","plt.imshow(cv2.cvtColor(img_pair_with_epilines_rect, cv2.COLOR_BGR2RGB))\n","plt.title('Rectified epipolar lines')\n","plt.axis('off')\n","plt.show()\n","\n","# Compute disparity map\n","a_gray = cv2.cvtColor(img1_rectified, cv2.COLOR_BGR2GRAY)\n","b_gray = cv2.cvtColor(img2_rectified, cv2.COLOR_BGR2GRAY)\n","a_gray = a_gray.astype(float)\n","b_gray = b_gray.astype(float)\n","h, w = a_gray.shape\n","\n","disparity_map = np.zeros((h, w))\n","BLOCK_SIZE = 7\n","SEARCH_BLOCK_SIZE = 56\n","\n","for y in tqdm(range(BLOCK_SIZE, h - BLOCK_SIZE)):\n","    for x in range(BLOCK_SIZE, w - BLOCK_SIZE):\n","        block_left = a_gray[y:y + BLOCK_SIZE, x:x + BLOCK_SIZE]\n","        min_index = compare_blocks(y, x, block_left, b_gray, BLOCK_SIZE, SEARCH_BLOCK_SIZE)\n","        disparity_map[y, x] = abs(min_index[1] - x)\n","\n","# Normalize disparity map for display\n","disparity = np.uint8(disparity_map * 255 / np.max(disparity_map))\n","\n","# Compute depth map\n","f = K1[0, 0]\n","baseline = 99.39\n","depth = (baseline * f) / (disparity_map + 1e-15)\n","depth[depth > 30000] = 30000\n","depth_map = np.uint8(depth * 255 / np.max(depth))\n","\n","# Display the results\n","plt.figure(figsize=(20, 15))\n","\n","# Display the disparity map\n","plt.subplot(2, 2, 1)\n","plt.imshow(disparity, cmap='gray')\n","plt.title('Disparity Map')\n","plt.colorbar()\n","\n","# Display the depth map\n","plt.subplot(2, 2, 2)\n","plt.imshow(depth_map, cmap='gray')\n","plt.title('Depth Map')\n","plt.colorbar()\n","\n","plt.tight_layout()\n","plt.show()\n","\n"],"metadata":{"id":"JL0_ekdHLcbV"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!cd /content && git clone 'https://github.com/verlab/accelerated_features.git'\n","%cd /content/accelerated_features"],"metadata":{"id":"ZGXPyI7Ofj3N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","\n","def warp_corners_and_draw_matches(ref_points, dst_points, img1, img2):\n","    # Calculate the Homography matrix\n","    H, mask = cv2.findHomography(ref_points, dst_points, cv2.USAC_MAGSAC, 3.5, maxIters=1_000, confidence=0.999)\n","    mask = mask.flatten()\n","\n","    # Get corners of the first image (image1)\n","    h, w = img1.shape[:2]\n","    corners_img1 = np.array([[0, 0], [w-1, 0], [w-1, h-1], [0, h-1]], dtype=np.float32).reshape(-1, 1, 2)\n","\n","    # Warp corners to the second image (image2) space\n","    warped_corners = cv2.perspectiveTransform(corners_img1, H)\n","\n","    # Draw the warped corners in image2\n","    img2_with_corners = img2.copy()\n","    for i in range(len(warped_corners)):\n","        start_point = tuple(warped_corners[i-1][0].astype(int))\n","        end_point = tuple(warped_corners[i][0].astype(int))\n","        cv2.line(img2_with_corners, start_point, end_point, (0, 255, 0), 5)  # Using solid green for corners\n","\n","    # Prepare keypoints and matches for drawMatches function\n","    keypoints1 = [cv2.KeyPoint(p[0], p[1], 10) for p in ref_points]\n","    keypoints2 = [cv2.KeyPoint(p[0], p[1], 10) for p in dst_points]\n","    matches = [cv2.DMatch(i,i,0) for i in range(len(mask)) if mask[i]]\n","\n","    # Draw inlier matches\n","    img_matches = cv2.drawMatches(img1, keypoints1, img2_with_corners, keypoints2, matches, None,\n","                                  matchColor=(0, 255, 255), flags=2)\n","\n","    return img_matches\n"],"metadata":{"id":"2sGjRZhnib-o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import os\n","import torch\n","import tqdm\n","import cv2\n","import matplotlib.pyplot as plt\n","\n","from modules.xfeat import XFeat\n","\n","xfeat = XFeat()\n","\n","#Load some example images\n","im1 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imLeft.png')\n","im2 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imRight.png')\n","\n","#Use out-of-the-box function for extraction + MNN matching\n","mkpts_0, mkpts_1 = xfeat.match_xfeat(im1, im2, top_k = 350)\n","\n","canvas = warp_corners_and_draw_matches(mkpts_0, mkpts_1, im1, im2)\n","plt.figure(figsize=(12,12))\n","plt.imshow(canvas[..., ::-1]), plt.show()"],"metadata":{"id":"Z8BvT25ieKlJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Use out-of-the-box function for extraction + coarse-to-fine matching\n","mkpts_0, mkpts_1 = xfeat.match_xfeat_star(im1, im2, top_k = 150)\n","\n","canvas = warp_corners_and_draw_matches(mkpts_0, mkpts_1, im1, im2)\n","plt.figure(figsize=(12,12))\n","plt.imshow(canvas[..., ::-1]), plt.show()"],"metadata":{"id":"KE5uPNU4eVTY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Function to perform preprocessing operations on the images\n","def preprocessing(img):\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    processed_img = cv2.GaussianBlur(gray, (5, 5), 0)\n","    return processed_img\n","\n","# Function to find features in the two images\n","def feature_detection(img1, img2):\n","    processed_img1, processed_img2 = preprocessing(img1), preprocessing(img2)\n","    sift = cv2.SIFT_create()\n","    kp1, desc1 = sift.detectAndCompute(processed_img1, None)\n","    kp2, desc2 = sift.detectAndCompute(processed_img2, None)\n","    bf = cv2.BFMatcher()\n","    matches = bf.knnMatch(desc1, desc2, k=2)\n","\n","    # Extracting good matches\n","    good = []\n","    for m, n in matches:\n","        if m.distance < 0.2 * n.distance:\n","            good.append(m)\n","\n","    left_pts = np.float32([kp1[m.queryIdx].pt for m in good])\n","    right_pts = np.float32([kp2[m.trainIdx].pt for m in good])\n","    return left_pts, right_pts, kp1, kp2, good\n","\n","# Function to compute Fundamental Matrix given feature points in two images\n","def fundamental_matrix(left_pts, right_pts):\n","    F, mask = cv2.findFundamentalMat(left_pts, right_pts, cv2.FM_RANSAC)\n","    return F, mask\n","\n","# Function to draw epilines on the images\n","def draw_epilines(img1, img2, lines, pts1, pts2):\n","    r, c = img1.shape\n","    img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n","    img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n","    for r, pt1, pt2 in zip(lines, pts1, pts2):\n","        color = tuple(np.random.randint(0, 255, 3).tolist())\n","        x0, y0 = map(int, [0, -r[2] / r[1]])\n","        x1, y1 = map(int, [c, -(r[2] + r[0] * c) / r[1]])\n","        img1 = cv2.line(img1, (x0, y0), (x1, y1), color, 1)\n","        img1 = cv2.circle(img1, (int(pt1[0]), int(pt1[1])), 5, color, -1)\n","        img2 = cv2.circle(img2, (int(pt2[0]), int(pt2[1])), 5, color, -1)\n","    return img1, img2\n","\n","# Load images\n","img1 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imLeft.png')\n","img2 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imRight.png')\n","\n","# Detect features and compute fundamental matrix using RANSAC\n","left_pts, right_pts, kp1, kp2, good = feature_detection(img1, img2)\n","F, mask = fundamental_matrix(left_pts, right_pts)\n","\n","# Select inlier points\n","left_pts = left_pts[mask.ravel() == 1]\n","right_pts = right_pts[mask.ravel() == 1]\n","\n","# Compute epilines for both images\n","lines1 = cv2.computeCorrespondEpilines(right_pts.reshape(-1, 1, 2), 2, F)\n","lines1 = lines1.reshape(-1, 3)\n","img1_with_lines, _ = draw_epilines(preprocessing(img1), preprocessing(img2), lines1, left_pts, right_pts)\n","\n","lines2 = cv2.computeCorrespondEpilines(left_pts.reshape(-1, 1, 2), 1, F)\n","lines2 = lines2.reshape(-1, 3)\n","img2_with_lines, _ = draw_epilines(preprocessing(img2), preprocessing(img1), lines2, right_pts, left_pts)\n","\n","# Display original images with epilines\n","plt.figure(figsize=(20, 10))\n","plt.subplot(121), plt.imshow(img1_with_lines), plt.title('Image gauche avec lignes épipolaires')\n","plt.subplot(122), plt.imshow(img2_with_lines), plt.title('Image droite avec lignes épipolaires')\n","plt.show()\n"],"metadata":{"id":"_mhysraU9RFW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Function to perform preprocessing operations on the images\n","def preprocessing(img):\n","    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    processed_img = cv2.GaussianBlur(gray, (5, 5), 0)\n","    return processed_img\n","\n","# Function to find features in the two images\n","def feature_detection(img1, img2):\n","    processed_img1, processed_img2 = preprocessing(img1), preprocessing(img2)\n","    sift = cv2.SIFT_create()\n","    kp1, desc1 = sift.detectAndCompute(processed_img1, None)\n","    kp2, desc2 = sift.detectAndCompute(processed_img2, None)\n","    bf = cv2.BFMatcher()\n","    matches = bf.knnMatch(desc1, desc2, k=2)\n","\n","    # Extracting good matches\n","    good = []\n","    for m, n in matches:\n","        if m.distance < 0.1 * n.distance:\n","            good.append(m)\n","\n","    left_pts = np.float32([kp1[m.queryIdx].pt for m in good])\n","    right_pts = np.float32([kp2[m.trainIdx].pt for m in good])\n","    return left_pts, right_pts, kp1, kp2, good\n","\n","# Function to compute Fundamental Matrix given feature points in two images\n","def fundamental_matrix(left_pts, right_pts):\n","    F, mask = cv2.findFundamentalMat(left_pts, right_pts, cv2.FM_RANSAC)\n","    return F, mask\n","\n","# Function to draw epilines on the images\n","def draw_epilines(img1, img2, lines, pts1, pts2):\n","    r, c = img1.shape\n","    img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n","    img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n","    for r, pt1, pt2 in zip(lines, pts1, pts2):\n","        color = tuple(np.random.randint(0, 255, 3).tolist())\n","        x0, y0 = map(int, [0, -r[2] / r[1]])\n","        x1, y1 = map(int, [c, -(r[2] + r[0] * c) / r[1]])\n","        img1 = cv2.line(img1, (x0, y0), (x1, y1), color, 2)\n","        img1 = cv2.circle(img1, (int(pt1[0]), int(pt1[1])), 3, color, -1)\n","        img2 = cv2.circle(img2, (int(pt2[0]), int(pt2[1])), 3, color, -1)\n","    return img1, img2\n","\n","# Load images\n","img1 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imLeft.png')\n","img2 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imRight.png')\n","\n","# Detect features and compute fundamental matrix using RANSAC\n","left_pts, right_pts, kp1, kp2, good = feature_detection(img1, img2)\n","F, mask = fundamental_matrix(left_pts, right_pts)\n","\n","# Select inlier points\n","left_pts = left_pts[mask.ravel() == 1]\n","right_pts = right_pts[mask.ravel() == 1]\n","\n","# Combine images side by side\n","img_combined = np.hstack((img1, img2))\n","gray_combined = cv2.cvtColor(img_combined, cv2.COLOR_BGR2GRAY)\n","\n","# Compute epilines for both images\n","lines1 = cv2.computeCorrespondEpilines(right_pts.reshape(-1, 1, 2), 2, F)\n","lines1 = lines1.reshape(-1, 3)\n","img1_with_lines, _ = draw_epilines(preprocessing(img1), preprocessing(img2), lines1, left_pts, right_pts)\n","\n","lines2 = cv2.computeCorrespondEpilines(left_pts.reshape(-1, 1, 2), 1, F)\n","lines2 = lines2.reshape(-1, 3)\n","img2_with_lines, _ = draw_epilines(preprocessing(img2), preprocessing(img1), lines2, right_pts, left_pts)\n","\n","# Combine images with epilines side by side\n","img_combined_with_lines = np.hstack((img1_with_lines, img2_with_lines))\n","\n","# Display combined image with epilines\n","plt.figure(figsize=(20, 10))\n","plt.imshow(img_combined_with_lines)\n","plt.title('Combined Image with Epipolar Lines')\n","plt.axis('off')\n","plt.show()\n","\n","# Stereo rectification\n","h1, w1 = img1.shape[:2]\n","_, H1, H2 = cv2.stereoRectifyUncalibrated(np.float32(left_pts), np.float32(right_pts), F, imgSize=(w1, h1))\n","\n","# Rectify the images\n","img1_rectified = cv2.warpPerspective(img1, H1, (w1, h1))\n","img2_rectified = cv2.warpPerspective(img2, H2, (w1, h1))\n","\n","# Combine rectified images side by side\n","img_combined_rectified = np.hstack((img1_rectified, img2_rectified))\n","\n","# Compute epilines for the rectified images\n","left_pts_rect = cv2.perspectiveTransform(left_pts.reshape(-1, 1, 2), H1).reshape(-1, 2)\n","right_pts_rect = cv2.perspectiveTransform(right_pts.reshape(-1, 1, 2), H2).reshape(-1, 2)\n","\n","lines1_rect = cv2.computeCorrespondEpilines(right_pts_rect.reshape(-1, 1, 2), 2, F)\n","lines1_rect = lines1_rect.reshape(-1, 3)\n","img1_rect_with_lines, _ = draw_epilines(preprocessing(img1_rectified), preprocessing(img2_rectified), lines1_rect, left_pts_rect, right_pts_rect)\n","\n","lines2_rect = cv2.computeCorrespondEpilines(left_pts_rect.reshape(-1, 1, 2), 1, F)\n","lines2_rect = lines2_rect.reshape(-1, 3)\n","img2_rect_with_lines, _ = draw_epilines(preprocessing(img2_rectified), preprocessing(img1_rectified), lines2_rect, right_pts_rect, left_pts_rect)\n","\n","# Combine rectified images with epilines side by side\n","img_combined_rect_with_lines = np.hstack((img1_rect_with_lines, img2_rect_with_lines))\n","\n","# Display rectified combined images with epilines\n","plt.figure(figsize=(20, 10))\n","plt.imshow(img_combined_rect_with_lines)\n","plt.title('Rectified Combined Image with Epipolar Lines')\n","plt.axis('off')\n","plt.show()\n","\n","# Compute disparity map\n","a_gray = cv2.cvtColor(img1_rectified, cv2.COLOR_BGR2GRAY)\n","b_gray = cv2.cvtColor(img2_rectified, cv2.COLOR_BGR2GRAY)\n","stereo = cv2.StereoBM_create(numDisparities=16, blockSize=15)\n","disparity = stereo.compute(a_gray, b_gray)\n","\n","# Normalize disparity map for display\n","disparity = cv2.normalize(disparity, disparity, alpha=0, beta=255, norm_type=cv2.NORM_MINMAX)\n","disparity = np.uint8(disparity)\n","\n","# Display disparity map\n","plt.figure(figsize=(10, 5))\n","plt.imshow(disparity, cmap='gray')\n","plt.title('Disparity Map')\n","plt.axis('off')\n","plt.show()\n"],"metadata":{"id":"uk5LU3Lp-SQ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Function to find features in the two images\n","def feature_detection(img1, img2):\n","    sift = cv2.SIFT_create()\n","    kp1, desc1 = sift.detectAndCompute(img1, None)\n","    kp2, desc2 = sift.detectAndCompute(img2, None)\n","    bf = cv2.BFMatcher()\n","    matches = bf.knnMatch(desc1, desc2, k=2)\n","\n","    # Extracting good matches\n","    good = []\n","    for m, n in matches:\n","        if m.distance < 0.1 * n.distance:\n","            good.append(m)\n","\n","    left_pts = np.float32([kp1[m.queryIdx].pt for m in good])\n","    right_pts = np.float32([kp2[m.trainIdx].pt for m in good])\n","    return left_pts, right_pts, kp1, kp2, good\n","\n","# Function to compute Fundamental Matrix given feature points in two images\n","def fundamental_matrix(left_pts, right_pts):\n","    F, mask = cv2.findFundamentalMat(left_pts, right_pts, cv2.FM_RANSAC)\n","    return F, mask\n","\n","# Function to draw epilines on the images\n","def draw_epilines(img1, img2, lines, pts1, pts2):\n","    r, c = img1.shape\n","    img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n","    img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n","    for r, pt1, pt2 in zip(lines, pts1, pts2):\n","        color = tuple(np.random.randint(0, 255, 3).tolist())\n","        x0, y0 = map(int, [0, -r[2] / r[1]])\n","        x1, y1 = map(int, [c, -(r[2] + r[0] * c) / r[1]])\n","        img1 = cv2.line(img1, (x0, y0), (x1, y1), color, 2)\n","        img1 = cv2.circle(img1, (int(pt1[0]), int(pt1[1])), 3, color, -1)\n","        img2 = cv2.circle(img2, (int(pt2[0]), int(pt2[1])), 3, color, -1)\n","    return img1, img2\n","\n","# Load images\n","img1 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imLeft.png', cv2.IMREAD_GRAYSCALE)\n","img2 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imRight.png', cv2.IMREAD_GRAYSCALE)\n","\n","# Detect features and compute fundamental matrix using RANSAC\n","left_pts, right_pts, kp1, kp2, good = feature_detection(img1, img2)\n","F, mask = fundamental_matrix(left_pts, right_pts)\n","\n","# Select inlier points\n","left_pts = left_pts[mask.ravel() == 1]\n","right_pts = right_pts[mask.ravel() == 1]\n","\n","# Compute epilines for both images\n","lines1 = cv2.computeCorrespondEpilines(right_pts.reshape(-1, 1, 2), 2, F)\n","lines1 = lines1.reshape(-1, 3)\n","img1_with_lines, _ = draw_epilines(img1, img2, lines1, left_pts, right_pts)\n","\n","lines2 = cv2.computeCorrespondEpilines(left_pts.reshape(-1, 1, 2), 1, F)\n","lines2 = lines2.reshape(-1, 3)\n","img2_with_lines, _ = draw_epilines(img2, img1, lines2, right_pts, left_pts)\n","\n","# Combine images with epilines side by side\n","img_combined_with_lines = np.hstack((img1_with_lines, img2_with_lines))\n","\n","# Display combined image with epilines\n","plt.figure(figsize=(20, 10))\n","plt.imshow(img_combined_with_lines)\n","plt.title('Combined Image with Epipolar Lines (Without Rectification)')\n","plt.axis('off')\n","plt.savefig('/content/drive/MyDrive/COMPUTER_VISION/')\n","plt.show()\n","\n","# Stereo rectification\n","h1, w1 = img1.shape[:2]\n","_, H1, H2 = cv2.stereoRectifyUncalibrated(np.float32(left_pts), np.float32(right_pts), F, imgSize=(w1, h1))\n","\n","# Rectify the images\n","img1_rectified = cv2.warpPerspective(img1, H1, (w1, h1))\n","img2_rectified = cv2.warpPerspective(img2, H2, (w1, h1))\n","\n","# Combine rectified images side by side\n","img_combined_rectified = np.hstack((img1_rectified, img2_rectified))\n","\n","# Compute epilines for the rectified images\n","left_pts_rect = cv2.perspectiveTransform(left_pts.reshape(-1, 1, 2), H1).reshape(-1, 2)\n","right_pts_rect = cv2.perspectiveTransform(right_pts.reshape(-1, 1, 2), H2).reshape(-1, 2)\n","\n","lines1_rect = cv2.computeCorrespondEpilines(right_pts_rect.reshape(-1, 1, 2), 2, F)\n","lines1_rect = lines1_rect.reshape(-1, 3)\n","img1_rect_with_lines, _ = draw_epilines(img1_rectified, img2_rectified, lines1_rect, left_pts_rect, right_pts_rect)\n","\n","lines2_rect = cv2.computeCorrespondEpilines(left_pts_rect.reshape(-1, 1, 2), 1, F)\n","lines2_rect = lines2_rect.reshape(-1, 3)\n","img2_rect_with_lines, _ = draw_epilines(img2_rectified, img1_rectified, lines2_rect, right_pts_rect, left_pts_rect)\n","\n","# Combine rectified images with epilines side by side\n","img_combined_rect_with_lines = np.hstack((img1_rect_with_lines, img2_rect_with_lines))\n","\n","# Display rectified combined images with epilines\n","plt.figure(figsize=(20, 10))\n","plt.imshow(img_combined_rect_with_lines)\n","plt.title('Rectified Combined Image with Epipolar Lines')\n","plt.axis('off')\n","plt.savefig('/content/drive/MyDrive/COMPUTER_VISION/')\n","plt.show()\n"],"metadata":{"id":"vu2LtTCzG6OK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Lecture des deux images\n","img1 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imLeft.png')\n","img2 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imRight.png')\n","\n","# Conversion en niveaux de gris\n","gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n","gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n","\n","# Détection des points d'intérêt\n","sift = cv2.SIFT_create()\n","kp1, des1 = sift.detectAndCompute(gray1, None)\n","kp2, des2 = sift.detectAndCompute(gray2, None)\n","\n","# Appariement des points d'intérêt\n","bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n","matches = bf.match(des1, des2)\n","matches = sorted(matches, key=lambda x: x.distance)\n","\n","# Extraction des points appariés\n","pts1 = np.float32([kp1[m.queryIdx].pt for m in matches])\n","pts2 = np.float32([kp2[m.trainIdx].pt for m in matches])\n","\n","# Calcul de la matrice fondamentale\n","F, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC)\n","\n","# Sélection des bons appariements\n","pts1 = pts1[mask.ravel() == 1]\n","pts2 = pts2[mask.ravel() == 1]\n","\n","# Affichage des lignes épipolaires avant rectification\n","def draw_epilines(img1, img2, lines, pts1, pts2):\n","    r, c = img1.shape[:2]\n","    img1_color = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n","    img2_color = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n","    for r, pt1, pt2 in zip(lines, pts1, pts2):\n","        color = tuple(np.random.randint(0, 255, 3).tolist())\n","        x0, y0 = map(int, [0, -r[2] / r[1]])\n","        x1, y1 = map(int, [c, -(r[2] + r[0] * c) / r[1]])\n","        img1_color = cv2.line(img1_color, (x0, y0), (x1, y1), color, 1)\n","        img1_color = cv2.circle(img1_color, tuple(map(int, pt1)), 5, color, -1)\n","        img2_color = cv2.circle(img2_color, tuple(map(int, pt2)), 5, color, -1)\n","    return img1_color, img2_color\n","\n","# Calcul des lignes épipolaires\n","lines1 = cv2.computeCorrespondEpilines(pts2.reshape(-1, 1, 2), 2, F)\n","lines1 = lines1.reshape(-1, 3)\n","img1_epilines, img2_epilines = draw_epilines(gray1, gray2, lines1, pts1, pts2)\n","\n","lines2 = cv2.computeCorrespondEpilines(pts1.reshape(-1, 1, 2), 1, F)\n","lines2 = lines2.reshape(-1, 3)\n","img2_epilines, img1_epilines = draw_epilines(gray2, gray1, lines2, pts2, pts1)\n","\n","# Affichage des images avec lignes épipolaires\n","plt.figure(figsize=(15, 5))\n","plt.subplot(121), plt.imshow(img1_epilines)\n","plt.subplot(122), plt.imshow(img2_epilines)\n","plt.suptitle('Lignes épipolaires avant rectification')\n","plt.show()\n","\n","# Rectification des images\n","h1, w1 = gray1.shape\n","h2, w2 = gray2.shape\n","\n","_, H1, H2 = cv2.stereoRectifyUncalibrated(np.float32(pts1), np.float32(pts2), F, imgSize=(w1, h1))\n","\n","img1_rectified = cv2.warpPerspective(img1, H1, (w1, h1))\n","img2_rectified = cv2.warpPerspective(img2, H2, (w2, h2))\n","\n","gray1_rectified = cv2.warpPerspective(gray1, H1, (w1, h1))\n","gray2_rectified = cv2.warpPerspective(gray2, H2, (w2, h2))\n","\n","# Recalcul des points appariés après rectification\n","kp1_rectified, des1_rectified = sift.detectAndCompute(gray1_rectified, None)\n","kp2_rectified, des2_rectified = sift.detectAndCompute(gray2_rectified, None)\n","matches_rectified = bf.match(des1_rectified, des2_rectified)\n","matches_rectified = sorted(matches_rectified, key=lambda x: x.distance)\n","\n","pts1_rectified = np.float32([kp1_rectified[m.queryIdx].pt for m in matches_rectified])\n","pts2_rectified = np.float32([kp2_rectified[m.trainIdx].pt for m in matches_rectified])\n","\n","# Affichage des lignes épipolaires après rectification\n","lines1_rectified = cv2.computeCorrespondEpilines(pts2_rectified.reshape(-1, 1, 2), 2, F)\n","lines1_rectified = lines1_rectified.reshape(-1, 3)\n","img1_rect_epilines, img2_rect_epilines = draw_epilines(gray1_rectified, gray2_rectified, lines1_rectified, pts1_rectified, pts2_rectified)\n","\n","lines2_rectified = cv2.computeCorrespondEpilines(pts1_rectified.reshape(-1, 1, 2), 1, F)\n","lines2_rectified = lines2_rectified.reshape(-1, 3)\n","img2_rect_epilines, img1_rect_epilines = draw_epilines(gray2_rectified, gray1_rectified, lines2_rectified, pts2_rectified, pts1_rectified)\n","\n","# Affichage des images rectifiées avec lignes épipolaires\n","plt.figure(figsize=(15, 5))\n","plt.subplot(121), plt.imshow(img1_rect_epilines)\n","plt.subplot(122), plt.imshow(img2_rect_epilines)\n","plt.suptitle('Lignes épipolaires après rectification')\n","plt.show()\n"],"metadata":{"id":"6EOX7N0fNH7m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Lecture des deux images\n","img1 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imLeft.png')\n","img2 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imRight.png')\n","\n","# Conversion en niveaux de gris\n","gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n","gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n","\n","# Détection des points d'intérêt\n","sift = cv2.SIFT_create()\n","kp1, des1 = sift.detectAndCompute(gray1, None)\n","kp2, des2 = sift.detectAndCompute(gray2, None)\n","\n","# Appariement des points d'intérêt\n","bf = cv2.BFMatcher(cv2.NORM_L2, crossCheck=True)\n","matches = bf.match(des1, des2)\n","matches = sorted(matches, key=lambda x: x.distance)\n","\n","# Extraction des points appariés\n","pts1 = np.float32([kp1[m.queryIdx].pt for m in matches])\n","pts2 = np.float32([kp2[m.trainIdx].pt for m in matches])\n","\n","# Calcul de la matrice fondamentale\n","F, mask = cv2.findFundamentalMat(pts1, pts2, cv2.FM_RANSAC)\n","\n","# Sélection des bons appariements\n","pts1 = pts1[mask.ravel() == 1]\n","pts2 = pts2[mask.ravel() == 1]\n","\n","# Fonction pour dessiner les lignes épipolaires\n","def draw_epilines(img1, img2, lines, pts1, pts2):\n","    r, c = img1.shape[:2]\n","    img1_color = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n","    img2_color = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n","    for r, pt1, pt2 in zip(lines, pts1, pts2):\n","        color = tuple(np.random.randint(0, 255, 3).tolist())\n","        x0, y0 = map(int, [0, -r[2] / r[1]])\n","        x1, y1 = map(int, [c, -(r[2] + r[0] * c) / r[1]])\n","        img1_color = cv2.line(img1_color, (x0, y0), (x1, y1), color, 1)\n","        img1_color = cv2.circle(img1_color, tuple(map(int, pt1)), 5, color, -1)\n","        img2_color = cv2.circle(img2_color, tuple(map(int, pt2)), 5, color, -1)\n","    return img1_color, img2_color\n","\n","# Calcul des lignes épipolaires\n","lines1 = cv2.computeCorrespondEpilines(pts2.reshape(-1, 1, 2), 2, F)\n","lines1 = lines1.reshape(-1, 3)\n","img1_epilines, img2_epilines = draw_epilines(gray1, gray2, lines1, pts1, pts2)\n","\n","# Combinaison des images avant rectification\n","combined_before = np.hstack((img1_epilines, img2_epilines))\n","\n","# Rectification des images\n","h1, w1 = gray1.shape\n","h2, w2 = gray2.shape\n","\n","_, H1, H2 = cv2.stereoRectifyUncalibrated(np.float32(pts1), np.float32(pts2), F, imgSize=(w1, h1))\n","\n","img1_rectified = cv2.warpPerspective(img1, H1, (w1, h1))\n","img2_rectified = cv2.warpPerspective(img2, H2, (w2, h2))\n","\n","gray1_rectified = cv2.warpPerspective(gray1, H1, (w1, h1))\n","gray2_rectified = cv2.warpPerspective(gray2, H2, (w2, h2))\n","\n","# Recalcul des points appariés après rectification\n","kp1_rectified, des1_rectified = sift.detectAndCompute(gray1_rectified, None)\n","kp2_rectified, des2_rectified = sift.detectAndCompute(gray2_rectified, None)\n","matches_rectified = bf.match(des1_rectified, des2_rectified)\n","matches_rectified = sorted(matches_rectified, key=lambda x: x.distance)\n","\n","pts1_rectified = np.float32([kp1_rectified[m.queryIdx].pt for m in matches_rectified])\n","pts2_rectified = np.float32([kp2_rectified[m.trainIdx].pt for m in matches_rectified])\n","\n","# Affichage des lignes épipolaires après rectification\n","lines1_rectified = cv2.computeCorrespondEpilines(pts2_rectified.reshape(-1, 1, 2), 2, F)\n","lines1_rectified = lines1_rectified.reshape(-1, 3)\n","img1_rect_epilines, img2_rect_epilines = draw_epilines(gray1_rectified, gray2_rectified, lines1_rectified, pts1_rectified, pts2_rectified)\n","\n","# Combinaison des images après rectification\n","combined_after = np.hstack((img1_rect_epilines, img2_rect_epilines))\n","\n","# Affichage des résultats\n","plt.figure(figsize=(15, 5))\n","plt.subplot(121)\n","plt.imshow(combined_before, cmap='gray')\n","plt.title('Lignes épipolaires avant rectification')\n","plt.subplot(122)\n","plt.imshow(combined_after, cmap='gray')\n","plt.title('Lignes épipolaires après rectification')\n","plt.show()\n"],"metadata":{"id":"BKeMniSpOL-o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Function to find features in the two images\n","def feature_detection(img1, img2):\n","    sift = cv2.SIFT_create()\n","    kp1, desc1 = sift.detectAndCompute(img1, None)\n","    kp2, desc2 = sift.detectAndCompute(img2, None)\n","    bf = cv2.BFMatcher()\n","    matches = bf.knnMatch(desc1, desc2, k=2)\n","\n","    # Extracting good matches\n","    good = []\n","    for m, n in matches:\n","        if m.distance < 0.1 * n.distance:\n","            good.append(m)\n","\n","    left_pts = np.float32([kp1[m.queryIdx].pt for m in good])\n","    right_pts = np.float32([kp2[m.trainIdx].pt for m in good])\n","    return left_pts, right_pts, kp1, kp2, good\n","\n","# Function to compute Fundamental Matrix given feature points in two images\n","def fundamental_matrix(left_pts, right_pts):\n","    F, mask = cv2.findFundamentalMat(left_pts, right_pts, cv2.FM_RANSAC)\n","    return F, mask\n","\n","# Function to draw epilines on the images\n","def draw_epilines(img1, img2, lines, pts1, pts2):\n","    r, c = img1.shape\n","    img1 = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n","    img2 = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n","    for r, pt1, pt2 in zip(lines, pts1, pts2):\n","        color = tuple(np.random.randint(0, 255, 3).tolist())\n","        x0, y0 = map(int, [0, -r[2] / r[1]])\n","        x1, y1 = map(int, [c, -(r[2] + r[0] * c) / r[1]])\n","        img1 = cv2.line(img1, (x0, y0), (x1, y1), color, 2)\n","        img1 = cv2.circle(img1, (int(pt1[0]), int(pt1[1])), 3, color, -1)\n","        img2 = cv2.circle(img2, (int(pt2[0]), int(pt2[1])), 3, color, -1)\n","    return img1, img2\n","\n","# Load images\n","img1 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imLeft.png', cv2.IMREAD_GRAYSCALE)\n","img2 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imRight.png', cv2.IMREAD_GRAYSCALE)\n","\n","# Detect features and compute fundamental matrix using RANSAC\n","left_pts, right_pts, kp1, kp2, good = feature_detection(img1, img2)\n","F, mask = fundamental_matrix(left_pts, right_pts)\n","\n","# Select inlier points\n","left_pts = left_pts[mask.ravel() == 1]\n","right_pts = right_pts[mask.ravel() == 1]\n","\n","# Compute epilines for both images\n","lines1 = cv2.computeCorrespondEpilines(right_pts.reshape(-1, 1, 2), 2, F)\n","lines1 = lines1.reshape(-1, 3)\n","img1_with_lines, img2_with_lines = draw_epilines(img1, img2, lines1, left_pts, right_pts)\n","\n","lines2 = cv2.computeCorrespondEpilines(left_pts.reshape(-1, 1, 2), 1, F)\n","lines2 = lines2.reshape(-1, 3)\n","img2_with_lines, img1_with_lines = draw_epilines(img2, img1, lines2, right_pts, left_pts)\n","\n","# Combine images with epilines side by side\n","img_combined_with_lines = np.hstack((img1_with_lines, img2_with_lines))\n","\n","# Display combined image with epilines\n","plt.figure(figsize=(20, 10))\n","plt.imshow(img_combined_with_lines)\n","plt.title('Combined Image with Epipolar Lines (Without Rectification)')\n","plt.axis('off')\n","plt.savefig('/content/drive/MyDrive/COMPUTER_VISION/epilines_without_rectification.png')\n","plt.show()\n","\n","# Stereo rectification\n","h1, w1 = img1.shape[:2]\n","_, H1, H2 = cv2.stereoRectifyUncalibrated(np.float32(left_pts), np.float32(right_pts), F, imgSize=(w1, h1))\n","\n","# Rectify the images\n","img1_rectified = cv2.warpPerspective(img1, H1, (w1, h1))\n","img2_rectified = cv2.warpPerspective(img2, H2, (w1, h1))\n","\n","# Combine rectified images side by side\n","img_combined_rectified = np.hstack((img1_rectified, img2_rectified))\n","\n","# Compute epilines for the rectified images\n","left_pts_rect = cv2.perspectiveTransform(left_pts.reshape(-1, 1, 2), H1).reshape(-1, 2)\n","right_pts_rect = cv2.perspectiveTransform(right_pts.reshape(-1, 1, 2), H2).reshape(-1, 2)\n","\n","lines1_rect = cv2.computeCorrespondEpilines(right_pts_rect.reshape(-1, 1, 2), 2, F)\n","lines1_rect = lines1_rect.reshape(-1, 3)\n","img1_rect_with_lines, img2_rect_with_lines = draw_epilines(img1_rectified, img2_rectified, lines1_rect, left_pts_rect, right_pts_rect)\n","\n","lines2_rect = cv2.computeCorrespondEpilines(left_pts_rect.reshape(-1, 1, 2), 1, F)\n","lines2_rect = lines2_rect.reshape(-1, 3)\n","img2_rect_with_lines, img1_rect_with_lines = draw_epilines(img2_rectified, img1_rectified, lines2_rect, right_pts_rect, left_pts_rect)\n","\n","# Combine rectified images with epilines side by side\n","img_combined_rect_with_lines = np.hstack((img1_rect_with_lines, img2_rect_with_lines))\n","\n","# Display rectified combined images with epilines\n","plt.figure(figsize=(20, 10))\n","plt.imshow(img_combined_rect_with_lines)\n","plt.title('Rectified Combined Image with Epipolar Lines')\n","plt.axis('off')\n","plt.savefig('/content/drive/MyDrive/COMPUTER_VISION/epilines_with_rectification.png')\n","plt.show()\n"],"metadata":{"id":"ZyPXZ3JMPMul"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Function to find features in the two images\n","def feature_detection(img1, img2):\n","    sift = cv2.SIFT_create()\n","    kp1, desc1 = sift.detectAndCompute(img1, None)\n","    kp2, desc2 = sift.detectAndCompute(img2, None)\n","    bf = cv2.BFMatcher()\n","    matches = bf.knnMatch(desc1, desc2, k=2)\n","\n","    # Extracting good matches\n","    good = []\n","    for m, n in matches:\n","        if m.distance < 0.1 * n.distance:\n","            good.append(m)\n","\n","    left_pts = np.float32([kp1[m.queryIdx].pt for m in good])\n","    right_pts = np.float32([kp2[m.trainIdx].pt for m in good])\n","    return left_pts, right_pts, kp1, kp2, good\n","\n","# Function to compute Fundamental Matrix given feature points in two images\n","def fundamental_matrix(left_pts, right_pts):\n","    F, mask = cv2.findFundamentalMat(left_pts, right_pts, cv2.FM_RANSAC)\n","    return F, mask\n","\n","# Function to draw epilines on the images\n","def draw_epilines(img1, img2, lines, pts1, pts2):\n","    r, c = img1.shape\n","    img1_color = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n","    img2_color = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n","    for r, pt1, pt2 in zip(lines, pts1, pts2):\n","        color = tuple(np.random.randint(0, 255, 3).tolist())\n","        x0, y0 = map(int, [0, -r[2] / r[1]])\n","        x1, y1 = map(int, [c, -(r[2] + r[0] * c) / r[1]])\n","        img1_color = cv2.line(img1_color, (x0, y0), (x1, y1), color, 2)\n","        img2_color = cv2.line(img2_color, (x0, y0), (x1, y1), color, 2)\n","        img1_color = cv2.circle(img1_color, (int(pt1[0]), int(pt1[1])), 3, color, -1)\n","        img2_color = cv2.circle(img2_color, (int(pt2[0]), int(pt2[1])), 3, color, -1)\n","    return img1_color, img2_color\n","\n","# Load images\n","img1 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imLeft.png', cv2.IMREAD_GRAYSCALE)\n","img2 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imRight.png', cv2.IMREAD_GRAYSCALE)\n","\n","# Detect features and compute fundamental matrix using RANSAC\n","left_pts, right_pts, kp1, kp2, good = feature_detection(img1, img2)\n","F, mask = fundamental_matrix(left_pts, right_pts)\n","\n","# Select inlier points\n","left_pts = left_pts[mask.ravel() == 1]\n","right_pts = right_pts[mask.ravel() == 1]\n","\n","# Compute epilines for both images\n","lines1 = cv2.computeCorrespondEpilines(right_pts.reshape(-1, 1, 2), 2, F)\n","lines1 = lines1.reshape(-1, 3)\n","img1_with_lines, img2_with_lines = draw_epilines(img1, img2, lines1, left_pts, right_pts)\n","\n","lines2 = cv2.computeCorrespondEpilines(left_pts.reshape(-1, 1, 2), 1, F)\n","lines2 = lines2.reshape(-1, 3)\n","img2_with_lines, img1_with_lines = draw_epilines(img2, img1, lines2, right_pts, left_pts)\n","\n","# Combine images with epilines side by side\n","img_combined_with_lines = np.hstack((img1_with_lines, img2_with_lines))\n","\n","# Display combined image with epilines\n","plt.figure(figsize=(20, 10))\n","plt.imshow(img_combined_with_lines)\n","plt.title('Combined Image with Epipolar Lines (Without Rectification)')\n","plt.axis('off')\n","plt.savefig('/content/drive/MyDrive/COMPUTER_VISION/epilines_without_rectification.png')\n","plt.show()\n","\n","# Stereo rectification\n","h1, w1 = img1.shape[:2]\n","_, H1, H2 = cv2.stereoRectifyUncalibrated(np.float32(left_pts), np.float32(right_pts), F, imgSize=(w1, h1))\n","\n","# Rectify the images\n","img1_rectified = cv2.warpPerspective(img1, H1, (w1, h1))\n","img2_rectified = cv2.warpPerspective(img2, H2, (w1, h1))\n","\n","# Combine rectified images side by side\n","img_combined_rectified = np.hstack((img1_rectified, img2_rectified))\n","\n","# Compute epilines for the rectified images\n","left_pts_rect = cv2.perspectiveTransform(left_pts.reshape(-1, 1, 2), H1).reshape(-1, 2)\n","right_pts_rect = cv2.perspectiveTransform(right_pts.reshape(-1, 1, 2), H2).reshape(-1, 2)\n","\n","lines1_rect = cv2.computeCorrespondEpilines(right_pts_rect.reshape(-1, 1, 2), 2, F)\n","lines1_rect = lines1_rect.reshape(-1, 3)\n","img1_rect_with_lines, img2_rect_with_lines = draw_epilines(img1_rectified, img2_rectified, lines1_rect, left_pts_rect, right_pts_rect)\n","\n","lines2_rect = cv2.computeCorrespondEpilines(left_pts_rect.reshape(-1, 1, 2), 1, F)\n","lines2_rect = lines2_rect.reshape(-1, 3)\n","img2_rect_with_lines, img1_rect_with_lines = draw_epilines(img2_rectified, img1_rectified, lines2_rect, right_pts_rect, left_pts_rect)\n","\n","# Combine rectified images with epilines side by side\n","img_combined_rect_with_lines = np.hstack((img1_rect_with_lines, img2_rect_with_lines))\n","\n","# Display rectified combined images with epilines\n","plt.figure(figsize=(20, 10))\n","plt.imshow(img_combined_rect_with_lines)\n","plt.title('Rectified Combined Image with Epipolar Lines')\n","plt.axis('off')\n","plt.savefig('/content/drive/MyDrive/COMPUTER_VISION/epilines_with_rectification.png')\n","plt.show()\n"],"metadata":{"id":"wQA1rSjOTTzM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","# Function to find features in the two images\n","def feature_detection(img1, img2):\n","    sift = cv2.SIFT_create()\n","    kp1, desc1 = sift.detectAndCompute(img1, None)\n","    kp2, desc2 = sift.detectAndCompute(img2, None)\n","    bf = cv2.BFMatcher()\n","    matches = bf.knnMatch(desc1, desc2, k=2)\n","\n","    # Extracting good matches\n","    good = []\n","    for m, n in matches:\n","        if m.distance < 0.1 * n.distance:\n","            good.append(m)\n","\n","    left_pts = np.float32([kp1[m.queryIdx].pt for m in good])\n","    right_pts = np.float32([kp2[m.trainIdx].pt for m in good])\n","    return left_pts, right_pts, kp1, kp2, good\n","\n","# Function to compute Fundamental Matrix given feature points in two images\n","def fundamental_matrix(left_pts, right_pts):\n","    F, mask = cv2.findFundamentalMat(left_pts, right_pts, cv2.FM_RANSAC)\n","    return F, mask\n","\n","# Function to draw epilines on the images\n","def draw_epilines(img1, img2, lines, pts1, pts2, colors):\n","    r, c = img1.shape\n","    img1_color = cv2.cvtColor(img1, cv2.COLOR_GRAY2BGR)\n","    img2_color = cv2.cvtColor(img2, cv2.COLOR_GRAY2BGR)\n","    for r, pt1, pt2, color in zip(lines, pts1, pts2, colors):\n","        x0, y0 = map(int, [0, -r[2] / r[1]])\n","        x1, y1 = map(int, [c, -(r[2] + r[0] * c) / r[1]])\n","        img1_color = cv2.line(img1_color, (x0, y0), (x1, y1), color, 2)\n","        img2_color = cv2.line(img2_color, (x0, y0), (x1, y1), color, 2)\n","        img1_color = cv2.circle(img1_color, (int(pt1[0]), int(pt1[1])), 3, color, -1)\n","        img2_color = cv2.circle(img2_color, (int(pt2[0]), int(pt2[1])), 3, color, -1)\n","    return img1_color, img2_color\n","\n","# Load images\n","img1 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imLeft.png', cv2.IMREAD_GRAYSCALE)\n","img2 = cv2.imread('/content/drive/MyDrive/COMPUTER_VISION/imRight.png', cv2.IMREAD_GRAYSCALE)\n","\n","# Detect features and compute fundamental matrix using RANSAC\n","left_pts, right_pts, kp1, kp2, good = feature_detection(img1, img2)\n","F, mask = fundamental_matrix(left_pts, right_pts)\n","\n","# Select inlier points\n","left_pts = left_pts[mask.ravel() == 1]\n","right_pts = right_pts[mask.ravel() == 1]\n","\n","# Generate a fixed set of colors for correspondences\n","colors = [tuple(np.random.randint(0, 255, 3).tolist()) for _ in range(len(left_pts))]\n","\n","# Compute epilines for both images\n","lines1 = cv2.computeCorrespondEpilines(right_pts.reshape(-1, 1, 2), 2, F)\n","lines1 = lines1.reshape(-1, 3)\n","img1_with_lines, img2_with_lines = draw_epilines(img1, img2, lines1, left_pts, right_pts, colors)\n","\n","# Combine images with epilines side by side\n","img_combined_with_lines = np.hstack((img1_with_lines, img2_with_lines))\n","\n","# Display combined image with epilines\n","plt.figure(figsize=(20, 10))\n","plt.imshow(img_combined_with_lines)\n","plt.title('Combined Image with Epipolar Lines (Without Rectification)')\n","plt.axis('off')\n","plt.show()\n","\n","# Stereo rectification\n","h1, w1 = img1.shape[:2]\n","_, H1, H2 = cv2.stereoRectifyUncalibrated(np.float32(left_pts), np.float32(right_pts), F, imgSize=(w1, h1))\n","\n","# Rectify the images\n","img1_rectified = cv2.warpPerspective(img1, H1, (w1, h1))\n","img2_rectified = cv2.warpPerspective(img2, H2, (w1, h1))\n","\n","# Combine rectified images side by side\n","img_combined_rectified = np.hstack((img1_rectified, img2_rectified))\n","\n","# Compute epilines for the rectified images\n","left_pts_rect = cv2.perspectiveTransform(left_pts.reshape(-1, 1, 2), H1).reshape(-1, 2)\n","right_pts_rect = cv2.perspectiveTransform(right_pts.reshape(-1, 1, 2), H2).reshape(-1, 2)\n","\n","lines1_rect = cv2.computeCorrespondEpilines(right_pts_rect.reshape(-1, 1, 2), 2, F)\n","lines1_rect = lines1_rect.reshape(-1, 3)\n","img1_rect_with_lines, img2_rect_with_lines = draw_epilines(img1_rectified, img2_rectified, lines1_rect, left_pts_rect, right_pts_rect, colors)\n","\n","# Combine rectified images with epilines side by side\n","img_combined_rect_with_lines = np.hstack((img1_rect_with_lines, img2_rect_with_lines))\n","\n","# Display rectified combined images with epilines\n","plt.figure(figsize=(20, 10))\n","plt.imshow(img_combined_rect_with_lines)\n","plt.title('Rectified Combined Image with Epipolar Lines')\n","plt.axis('off')\n","plt.show()\n"],"metadata":{"id":"BtV3hlWEUd-v"},"execution_count":null,"outputs":[]}]}